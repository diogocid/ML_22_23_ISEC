{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %load utilities\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "\n",
    "df = pd.read_csv('loan_default_prediction.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop\n",
    "vdrop=['ID','Validation','Designation','Debt_to_Income','Postal_Code','Deprecatory_Records',\\\n",
    "            'Inquiries','Gross_Collection','Sub_GGGrade','Total_Unpaid_CL','File_Status','Claim_Type','Due_Fee']\n",
    "df=df.drop(vdrop,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversão dos anos de experiência para numérico\n",
    "df['Experience']=df['Experience'].apply(lambda i: 10 if i[0:1]=='>' else 1 if i[0:1]=='<' else int(i[0:1]))\n",
    "#Conversão da duração para numérico\n",
    "df['Duration']=df['Duration'].apply(lambda i : i.replace(' years','years')).astype(str)\n",
    "#Conversão da GGGrade valor ordinal para numérico\n",
    "df['GGGrade']=df['GGGrade'].apply(romanToInt).astype(int)\n",
    "#criacao de debt to income\n",
    "#calcular o total da divida e o rendimento anual. uma espécie de \"taxa de esforço\"\n",
    "df['debt_to_income']=df['Unpaid_Amount']/df['Yearly_Income']\n",
    "#ver resultado\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar observações com pelo menos uma feature sem valores\n",
    "df=df.dropna()\n",
    "#drop duplicates\n",
    "df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num_cont=['Asst_Reg','Experience','Yearly_Income','Lend_Amount','Interest_Charged','Usage_Rate',\n",
    "            'Present_Balance','Unpaid_Amount','debt_to_income']\n",
    "v_num_disc=['Unpaid_2_years','Already_Defaulted','Account_Open']\n",
    "v_cat_ord=['Home_Status','State','Reason','Duration']#,'GGGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "display(df.shape)\n",
    "#remover observações com home status 'none' e 'other'\n",
    "df=df[(df['Home_Status']!='OTHER')&(df['Home_Status']!='NONE')]\n",
    "#remover linhas com outliers, definidos como mais que 3 desvios-padrão acima/abaixo da média\n",
    "df=df[(np.abs(stats.zscore(df[v_num_cont])) < 3).all(axis=1)]\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver quantas observações têm default=1\n",
    "display((df['Default']==1).sum())\n",
    "#sample de 5000 obs com default =1\n",
    "defaulted = df[df['Default']==1].sample(n=5000, random_state=101)\n",
    "#sample de 5000 obs com default =0\n",
    "notdefault = df[df['Default']==0].sample(n=5000, random_state=101)\n",
    "#agregar as observações\n",
    "df = pd.concat([defaulted,notdefault],axis=0)\n",
    "#sort aleatório das obs\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[v_num_disc].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs test sample: standard and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "#QUANDO PIPELINE ESTIVER PARA TODAS AS VARIÁVEIS, MUDAR O X\n",
    "X = df[v_num_cont+v_num_disc+v_cat_ord]\n",
    "y = df['Default']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#script não ativado para fazer cross validation manual (normalmente o scikit learn faz tudo automático)\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = KFold(n_splits=5,shuffle=True)\n",
    "#for train_index, test_index in kfold.split(X):\n",
    "#    print(\"Train index:\", train_index, \"Test index:\", test_index)\n",
    "#    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "#    y_train, y_test = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a parte: tentar reduzir assimetria das variáveis\n",
    "\n",
    "#está suficientemente distante de 0 para ter certeza que é assimétrica\n",
    "#como se vê isso? quanto mais pequeno for o p-value (2a linha dataframe), mais certezas temos que é assimétrica\n",
    "\n",
    "#verificar assimetria das features numéricas\n",
    "dskew=skew_df(X_train[v_num_cont+v_num_disc])\n",
    "#mostrar output\n",
    "display(dskew)\n",
    "#ver lista de features assimétricas, pvalue < 5%\n",
    "v_skew=list(dskew.columns[dskew.loc['p_value']<0.05])\n",
    "#lista de simétricas são as restantes\n",
    "v_sym=list(set(X_train[v_num_cont+v_num_disc].columns) - set(v_skew))\n",
    "#check\n",
    "v_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=[]\n",
    "for i in v_cat_ord:\n",
    "    c=df[i].value_counts()/df.shape[0]\n",
    "    #list(c[c>.05].index)\n",
    "    print('Features com predominância em mais de 5% das observações:'+str(list(c[c>=.05].index)))\n",
    "    print('Features com predominância em menos de 5% das observações:'+str(list(c[c<.05].index)))\n",
    "    #cc=cc+c\n",
    "    \n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the transformations to apply to the column\n",
    "transformer = ColumnTransformer([\n",
    "    ('yeoj', PowerTransformer(), v_skew), #aplico transformação que corrige assimetria às assimétricas\n",
    "    ('std', StandardScaler(), v_sym),     #aplico transformação às simétricas (sub média e dividir desvio padrao)\n",
    "    ('oneh', OneHotEncoder(min_frequency=0.05,handle_unknown='ignore',#drop='if_biNameErrorary',\n",
    "                           sparse_output=False), v_cat_ord)\n",
    "])\n",
    "\n",
    "#pipeline= Pipeline([\n",
    "    #('ct', transformer),\n",
    "    #('to_df', pd.DataFrame, {'columns': v_skew+v_sym})\n",
    "    #(\"pandarizer\",FunctionTransformer(lambda x: pd.DataFrame(x, columns = (v_skew + v_sym))))\n",
    "#])\n",
    "\n",
    "# Transform the data\n",
    "pfit = transformer.fit(X_train)\n",
    "\n",
    "categories= pfit.transformers_[2][1].categories_\n",
    "categories_out=pfit.transformers_[2][1].infrequent_categories_\n",
    "\n",
    "v_onehot_drop=list(np.concatenate([np.concatenate([categories[i][np.isin(categories[i], categories_out[i], invert=True)]],axis=0) \n",
    "                        for i in range(0,len(categories))],axis=0))\n",
    "\n",
    "\n",
    "v_onehot=list(np.concatenate([(np.concatenate((np.array(j),\n",
    "                       (np.array(['Other_Cat'+str(k)]) if categories_out[k] is not None else np.array([]))),axis=0)) \n",
    "                         for k,j in enumerate(\n",
    "                         [np.concatenate([categories[i][np.isin(categories[i], categories_out[i], invert=True)]],axis=0) \n",
    "                        for i in range(0,len(categories))]\n",
    "                         )]))\n",
    "\n",
    "#X_train_transf = transformer.transform(X_train)\n",
    "X_train_transf = pd.DataFrame(pfit.transform(X_train),columns = (v_skew + v_sym+v_onehot)\n",
    "                              ,index=X_train.index)\n",
    "\n",
    "#aplicar transformações ao teste calcula\n",
    "#X_test_transf = transformer.transform(X_test)\n",
    "X_test_transf = pd.DataFrame(pfit.transform(X_test),columns = (v_skew + v_sym+v_onehot)\n",
    "                            ,index=X_test.index)\n",
    "\n",
    "display(round(X_train_transf.describe(),2))\n",
    "#vamos dar um check se o dataframe ficou \"menos assimétrico\"\n",
    "skew_df(X_train_transf[v_skew+v_sym])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classificator verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score, roc_curve\n",
    "#Não usar bernoulli porque faz mais sentido para variaveis binarias\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "#from seaborn as sns\n",
    "\n",
    "rnd_clf=RandomForestClassifier(n_estimators=100)\n",
    "log_clf=LogisticRegression()\n",
    "svm_clf=SVC()\n",
    "dtc_clf=DecisionTreeClassifier()\n",
    "knn_clf=KNeighborsClassifier()\n",
    "mpl_clf=MLPClassifier()\n",
    "gnb_clf=GaussianNB()\n",
    "#Adicionar o resto dos modelos superviselearning menos o xgboost\n",
    "#bnb_clf=BernoulliNB()\n",
    "\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "    estimators=[('lr',log_clf),('rf',rnd_clf),('svm',svm_clf)\n",
    "                ,('dtc',dtc_clf),('knn',knn_clf),('mpl',mpl_clf),('gnb',gnb_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    " \n",
    "dataMetrics = pd.DataFrame(columns=['Accuracy','Precision','Recall','F1'])\n",
    "for clf in (log_clf,rnd_clf,svm_clf,dtc_clf,knn_clf,mpl_clf,gnb_clf,voting_clf):\n",
    "    clf.fit(X_train_transf,y_train)\n",
    "    y_pred=clf.predict(X_test_transf)   \n",
    "    #DataFrame\n",
    "    dataMetrics.loc[clf.__class__.__name__, ['Accuracy']] = metrics.accuracy_score(y_test, y_pred).round(2)\n",
    "    dataMetrics.loc[clf.__class__.__name__, ['Precision']] = metrics.precision_score(y_test, y_pred).round(2)\n",
    "    dataMetrics.loc[clf.__class__.__name__, ['Recall']] = metrics.recall_score(y_test, y_pred).round(2)\n",
    "    dataMetrics.loc[clf.__class__.__name__, ['F1']] = metrics.f1_score(y_test, y_pred).round(2)\n",
    "    #Confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    #sns.heatmap(cf_matrix)\n",
    "    #Generate the ROC AUC Curve\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    #ROC AUC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n",
    "    \n",
    "dataMetrics\n",
    "    \n",
    "#experimentar pesos, fazer grid search\n",
    "\n",
    "#APLICAR TRAIN TEST UMAS 30 VEZES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionar cscript dos classificador com hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection/Unsupervise Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA to the training data to reduce the dimensionality\n",
    "#ALWAYS STANDARDIZE\n",
    "#VER SE VALE A PENA FAZER UNS GRAFICOS\n",
    "#POR EXEMPLO\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=0.9999)\n",
    "\n",
    "X_pca=pca.fit(X_train_transf[v_skew+v_sym])\n",
    "# Determine explained variance using explained_variance_ration_ attribute\n",
    "#\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "#\n",
    "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "# for visualizing the variance explained by each principal component.\n",
    "#\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "# Create the visualization plot\n",
    "#\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Use cross-validation to evaluate logistic regression with different numbers of principal components\n",
    "pca = PCA()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "n_components = range(1, X_train_transf[v_skew+v_sym].shape[1]+1)\n",
    "scores = []\n",
    "display(X_train_transf[v_skew+v_sym].shape[1])\n",
    "\n",
    "for n in n_components:\n",
    "    pca.n_components = n\n",
    "    X_train_pca = pca.fit_transform(X_train_transf[v_skew+v_sym])\n",
    "    score = np.mean(cross_val_score(logreg, X_train_pca, y_train, cv=5, scoring='f1'))\n",
    "    scores.append(score)\n",
    "\n",
    "# Select the number of components that gives the highest cross-validation score\n",
    "optimal_n_components = n_components[np.argmax(scores)]\n",
    "display(scores)\n",
    "#display(n_components)\n",
    "\n",
    "# Train logistic regression model on full training set with optimal number of components\n",
    "pca.n_components = optimal_n_components\n",
    "display(optimal_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=optimal_n_components)\n",
    "\n",
    "X_pca=pca.fit(X_train_transf[v_skew+v_sym])\n",
    "\n",
    "X_train_num_pca=pd.DataFrame(pca.transform(X_train_transf[v_skew+v_sym]),\n",
    "                         columns=['pca_v'+str(i+1) for i in range (0,X_pca.n_components_)],\n",
    "                        index=X_train_transf.index)\n",
    "\n",
    "X_test_num_pca=pd.DataFrame(pca.transform(X_test_transf[v_skew+v_sym]),\n",
    "                         columns=['pca_v'+str(i+1) for i in range (0,X_pca.n_components_)],\n",
    "                        index=X_test_transf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_pca=pd.concat([X_train_num_pca,pd.DataFrame(y_train)],axis=1)\n",
    "#display(df_pca.head(5))\n",
    "\n",
    "sns.scatterplot(x='pca_v1', y='pca_v2', hue='Default', data=df_pca);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_pca.corr()\n",
    "display(round(corr.iloc[[-1],:],2))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar X com PCA\n",
    "X_train_pca=pd.concat(\n",
    "    [X_train_num_pca,\n",
    "        X_train_transf[X_train_transf.columns[-(len(X_train_transf.columns)-len(v_skew+v_sym)):]]],\n",
    "     axis=1)\n",
    "\n",
    "X_test_pca=pd.concat(\n",
    "    [X_test_num_pca,\n",
    "        X_test_transf[X_test_transf.columns[-(len(X_test_transf.columns)-len(v_skew+v_sym)):]]],\n",
    "     axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse=[]\n",
    "silhscores = []\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "k_rng=range(1,15)\n",
    "for k in k_rng:\n",
    "    km=KMeans(n_clusters=k,n_init=10)\n",
    "    km.fit(X_train_transf)\n",
    "    sse.append(km.inertia_)\n",
    "    if k>1:\n",
    "        km_pred=km.predict(X_train_transf)\n",
    "        silhscore = silhouette_score(X_train_transf, km_pred)\n",
    "        silhscores.append(silhscore)\n",
    "display(silhscores)    \n",
    "sse\n",
    "\n",
    "#--Lento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('K')\n",
    "plt.ylabel('Sum of squared error')\n",
    "plt.xticks(k_rng)\n",
    "plt.plot(k_rng,sse, '-o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the silhouette scores\n",
    "plt.plot(range(2, 15), silhscores, '-o')\n",
    "plt.xticks(range(2, 15))\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters identified by silhouette\n",
    "k_silh=range(2,15)[np.array(silhscores).argmax()]\n",
    "display('The silhouette score has chosen '+str(k_silh)+' clusters.')\n",
    "km=KMeans(n_clusters=k_silh,n_init=10)\n",
    "km_fit=km.fit(X_train_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Centros dos clusters\n",
    "cluster=km_fit.predict(X_train_transf)\n",
    "unique, counts = np.unique(cluster, return_counts=True)\n",
    "display(pd.DataFrame(np.asarray((unique, counts)).T,columns=['cluster','no of obs']))\n",
    "\n",
    "#km_fit.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe\n",
    "ohe=OneHotEncoder(sparse=False)\n",
    "display(pd.concat([X_train_transf,pd.DataFrame(ohe.fit_transform(km_fit.labels_.reshape(-1, 1)),\n",
    "columns=['cluster'+str(i) for i in range(0,km_fit.labels_.max()+1)],\n",
    "                    index=X_train_transf.index)],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "C=[0.001, 0.01, 0.1, 1, 10, 100]\n",
    "scor=[]\n",
    "for k in range(2,15):\n",
    "    km=KMeans(n_clusters=k,n_init=10)\n",
    "    km_fit=km.fit(X_train_transf)\n",
    "    ohe=OneHotEncoder(sparse=False)\n",
    "    X_cluster=pd.concat([X_train_transf,pd.DataFrame(ohe.fit_transform(km_fit.labels_.reshape(-1, 1)),\n",
    "    columns=['cluster'+str(i) for i in range(0,km_fit.labels_.max()+1)],\n",
    "                    index=X_train_transf.index)],axis=1)\n",
    "    for i in C:\n",
    "        logistic_regression = LogisticRegression(C=i)\n",
    "        scor.append([k,i,cross_validate(logistic_regression, X_cluster, y_train, \n",
    "                           cv=5,scoring=['f1','recall'])['test_f1'].mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(scor)[np.array(scor)[:,2].argmax(),:]\n",
    "\n",
    "k_cv=np.array(scor)[np.array(scor)[:,2].argmax(),0].astype(int)\n",
    "C_cv=np.array(scor)[np.array(scor)[:,2].argmax(),1]\n",
    "\n",
    "km=KMeans(n_clusters=k_cv,n_init=10)\n",
    "km_fit=km.fit(X_train_transf)\n",
    "ohe=OneHotEncoder(sparse=False)\n",
    "X_cluster=pd.concat([X_train_transf,pd.DataFrame(ohe.fit_transform(km_fit.labels_.reshape(-1, 1)),\n",
    "columns=['cluster'+str(i) for i in range(0,km_fit.labels_.max()+1)],\n",
    "                    index=X_train_transf.index)],axis=1)\n",
    "display(X_cluster.head(5))\n",
    "\n",
    "cluster=km_fit.predict(X_train_transf)\n",
    "#cluster=km_fit.predict(X_train_transf)\n",
    "unique, counts = np.unique(cluster, return_counts=True)\n",
    "display(pd.DataFrame(np.asarray((unique, counts)).T,columns=['cluster','no of obs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_transf, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LinearSVC(loss='hinge',max_iter=10000)\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_transf, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [2,3 ,5, 10, 15, 20],\n",
    "    'min_samples_leaf': [2, 4, 6, 8],\n",
    "    'min_samples_split': [2, 4, 6, 8],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "tree_clf=DecisionTreeClassifier()\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(estimator=tree_clf, param_grid=param_grid, cv=5,scoring='f1')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "tree_clf_cv=grid_search.fit(X_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "display(tree_clf_cv.best_score_)\n",
    "print(tree_clf_cv.best_params_)\n",
    "best_tree_params=tree_clf_cv.best_params_\n",
    "best_tree=DecisionTreeClassifier(**best_tree_params)\n",
    "best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(best_tree.fit(X_train_transf, y_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data=export_graphviz(best_tree,feature_names=X_train_transf.columns,\n",
    "                         class_names=['no default','default'],\n",
    "                         filled=True)\n",
    "\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#não precisamos de adicionar hiperparametro devido ao facto de já termos a variancia normalizada das features\n",
    "#no limite, hiperparametros só no pré processamento, ajustadando no no de bins \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "est=KBinsDiscretizer(n_bins=5,encode='ordinal',strategy='quantile')\n",
    "est.fit(X_train_tranf)\n",
    "Xt_train=est.transform(X_train_transf)\n",
    "Xt_test=est.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnNB=MultinomialNB()\n",
    "mnNB.fit(Xt_train,y_train)\n",
    "y_pred=mnNB.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('discretizer', KBinsDiscretizer(encode='ordinal',strategy='quantile')),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {\n",
    "    'discretizer__n_bins': [3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_transf, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "display(grid_search.best_estimator_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "accuracy = best_model.score(X_test_transf, y_test)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gNB=MultinomialNB()\n",
    "gNB.fit(X_train_transf,y_train)\n",
    "y_pred=gNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#rf_clf=RandomForestClassifier()\n",
    "#rf_clf.fit(X_train_transf,y_train)\n",
    "#y_pred=rf_Model.predict(X_test_transf)\n",
    "\n",
    "param_grid={'n_estimators':[int(x) for x in np.linspace(10,100,4)],\n",
    "            'max_features':['auto','sqrt'],\n",
    "            'max_depth': [2, 3 ,5, 10],\n",
    "            'min_samples_leaf': [4, 6, 8],\n",
    "            'min_samples_split': [6, 8],\n",
    "            'bootstrap':[True,False]\n",
    "}\n",
    "\n",
    "rf_clf=RandomForestClassifier()\n",
    "\n",
    "# Create the grid search object\n",
    "rf_clf_gs = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5,scoring='f1',n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "rf_clf_cv=rf_clf_gs.fit(X_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "display(rf_clf_cv.best_score_)\n",
    "best_rf_params=rf_clf_cv.best_params_\n",
    "display(best_rf_params)\n",
    "best_rf=RandomForestClassifier(**best_rf_params)\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_Grid=GridSearchCV(rf_Model,param_grid,cv=5)\n",
    "rf_Grid.fit(X_train_transf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=rf_Grid.predict(X_test)\n",
    "rf_Grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train_transf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the parameter grid\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'leaf_size': [10, 30, 50, 70]\n",
    "}\n",
    "\n",
    "# Create the k-NN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create the grid search object\n",
    "knn_gs = GridSearchCV(estimator=knn, param_grid=knn_param_grid, cv=5,scoring='f1',n_jobs=-1)\n",
    "\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "knn_clf_cv=knn_gs.fit(X_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "display(knn_clf_cv.best_score_)\n",
    "best_knn_params=knn_clf_cv.best_params_\n",
    "display(best_knn_params)\n",
    "best_knn=KNeighborsClassifier(**best_knn_params)\n",
    "best_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# Define the parameters for the XGBoost model\n",
    "xgbo_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Create the k-NN classifier\n",
    "xgbo = xgb.XGBClassifier()\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test_transf)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "xgbo_clf_cv=xgbo_gs.fit(X_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "display(xgbo_clf_cv.best_score_)\n",
    "best_xgbo_params=xgbo_clf_cv.best_params_\n",
    "display(best_xgbo_params)\n",
    "best_xgbo=xgb.XGBClassifier(**best_xgbo_params)\n",
    "best_xgbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "mlp_param_grid = {'hidden_layer_sizes': [(6,),(8,),(5,),(10,), (20,), (30,), (40,)],\n",
    "              'solver': ['adam', 'sgd'],\n",
    "              'activation': ['relu', 'tanh','logistic']}\n",
    "\n",
    "mlp=MLPClassifier(max_iter=2000)\n",
    "\n",
    "# Create the grid search object\n",
    "mlp_gs = GridSearchCV(estimator=mlp, param_grid=mlp_param_grid, cv=5,scoring='f1',n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "mlp_clf_cv=mlp_gs.fit(X_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "display(mlp_clf_cv.best_score_)\n",
    "best_mlp_params=mlp_clf_cv.best_params_\n",
    "display(best_mlp_params)\n",
    "best_mlp=MLPClassifier(**best_mlp_params)\n",
    "best_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinação de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOTING\n",
    "\n",
    "#sklearn.ensemble.VotingClassifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit different models and evaluate their performance\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"{model.__class__.__name__}: {accuracy:.2f}\")\n",
    "    \n",
    "    #STACKING\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "# Define the second-level model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Define the stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = stacking_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "# Generate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "printCustomMetrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred)    \n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

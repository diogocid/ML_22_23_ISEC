{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Libraries used\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87500, 30)\n"
     ]
    }
   ],
   "source": [
    "#Import Dataset\n",
    "df = pd.read_csv('loan_default_prediction.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87500, 18)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop\n",
    "vdrop=['ID','Validation','Designation','Debt_to_Income','Postal_Code','Deprecatory_Records',\\\n",
    "            'Inquiries','Gross_Collection','Sub_GGGrade','Total_Unpaid_CL','File_Status','Claim_Type']\n",
    "df=df.drop(vdrop,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def romanToInt(i):\n",
    "    roman = {'I':1,'V':5,'X':10,'L':50,'C':100,'D':500,'M':1000,'IV':4,'IX':9,'XL':40,'XC':90,'CD':400,'CM':900}\n",
    "    j = 0\n",
    "    num = 0\n",
    "    while j < len(i):\n",
    "        if j+1<len(i) and i[j:j+2] in roman:\n",
    "            num+=roman[i[j:j+2]]\n",
    "            j+=2\n",
    "        else:\n",
    "\n",
    "            num+=roman[i[j]]\n",
    "            j+=1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversão dos anos de experiência para numérico\n",
    "df['Experience']=df['Experience'].apply(lambda i: 10 if i[0:1]=='>' else 1 if i[0:1]=='<' else int(i[0:1]))\n",
    "#Conversão da duração para numérico\n",
    "df['Duration']=df['Duration'].apply(lambda i : i.replace(' years','')).astype(int)\n",
    "#Conversão da GGGrade valor ordinal para numérico\n",
    "df['GGGrade']=df['GGGrade'].apply(romanToInt).astype(int)\n",
    "#ver resultado\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77376, 18)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar observações com pelo menos uma feature sem valores\n",
    "df=df.dropna()\n",
    "#drop duplicates\n",
    "df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>GGGrade</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Home_Status</th>\n",
       "      <th>Unpaid_2_years</th>\n",
       "      <th>Already_Defaulted</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>State</th>\n",
       "      <th>Account_Open</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421802</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>633600.00</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42023.25</td>\n",
       "      <td>15.39</td>\n",
       "      <td>88.924</td>\n",
       "      <td>607161.90</td>\n",
       "      <td>California</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>31216.05</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3964312</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>85483.20</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38133.00</td>\n",
       "      <td>9.94</td>\n",
       "      <td>102.856</td>\n",
       "      <td>269234.06</td>\n",
       "      <td>NC</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11660.49</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4247560</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>79200.00</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17100.00</td>\n",
       "      <td>22.35</td>\n",
       "      <td>60.372</td>\n",
       "      <td>22476.53</td>\n",
       "      <td>Florida</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5637.87</td>\n",
       "      <td>major  purchase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197179</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61600.00</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5130.00</td>\n",
       "      <td>10.36</td>\n",
       "      <td>116.272</td>\n",
       "      <td>15242.09</td>\n",
       "      <td>NewJersey</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>15607.17</td>\n",
       "      <td>major  purchase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646684</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>68053.92</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19665.00</td>\n",
       "      <td>13.68</td>\n",
       "      <td>127.280</td>\n",
       "      <td>65433.94</td>\n",
       "      <td>LA</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>27472.86</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asst_Reg  GGGrade  Experience  Yearly_Income Home_Status  Unpaid_2_years  \\\n",
       "0    421802        2          10      633600.00    MORTGAGE               0   \n",
       "1   3964312        4           7       85483.20        RENT               0   \n",
       "2   4247560        3           1       79200.00        RENT               0   \n",
       "3    197179        3           1       61600.00        RENT               0   \n",
       "4   4646684        5           2       68053.92        RENT               0   \n",
       "\n",
       "   Already_Defaulted  Lend_Amount  Interest_Charged  Usage_Rate  \\\n",
       "0                  0     42023.25             15.39      88.924   \n",
       "1                  0     38133.00              9.94     102.856   \n",
       "2                  0     17100.00             22.35      60.372   \n",
       "3                  0      5130.00             10.36     116.272   \n",
       "4                  0     19665.00             13.68     127.280   \n",
       "\n",
       "   Present_Balance       State  Account_Open  Duration  Unpaid_Amount  \\\n",
       "0        607161.90  California            17         3       31216.05   \n",
       "1        269234.06          NC            15         5       11660.49   \n",
       "2         22476.53     Florida             7         5        5637.87   \n",
       "3         15242.09   NewJersey             9         3       15607.17   \n",
       "4         65433.94          LA            10         5       27472.86   \n",
       "\n",
       "                Reason  Due_Fee  Default  \n",
       "0  debt  consolidation      0.0        0  \n",
       "1  debt  consolidation      0.0        0  \n",
       "2      major  purchase      0.0        0  \n",
       "3      major  purchase      0.0        1  \n",
       "4  debt  consolidation      0.0        0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.describe()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisão do dataset\n",
    "v_num_cont=['Asst_Reg','Experience','Yearly_Income','Lend_Amount','Interest_Charged','Usage_Rate',\n",
    "            'Present_Balance','Due_Fee','Unpaid_Amount']\n",
    "v_num_disc=['Unpaid_2_years','Already_Defaulted','Account_Open','Duration']\n",
    "v_cat_ord=['Home_Status','State','Reason','GGGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MORTGAGE    39077\n",
      "RENT        30853\n",
      "OWN          7436\n",
      "OTHER           6\n",
      "NONE            4\n",
      "Name: Home_Status, dtype: int64\n",
      "California    11194\n",
      "Newyork        6414\n",
      "TX             6307\n",
      "Florida        5149\n",
      "IL             3091\n",
      "NewJersey      2877\n",
      "PA             2797\n",
      "Ohio           2602\n",
      "GA             2572\n",
      "VA             2251\n",
      "NC             2230\n",
      "MI             1995\n",
      "Maryland       1857\n",
      "AZ             1797\n",
      "MA             1764\n",
      "CO             1685\n",
      "WA             1627\n",
      "MN             1493\n",
      "IN             1276\n",
      "MO             1253\n",
      "TN             1184\n",
      "CT             1172\n",
      "NV             1039\n",
      "AL              999\n",
      "WI              990\n",
      "OR              929\n",
      "LA              908\n",
      "SC              888\n",
      "KY              728\n",
      "KS              722\n",
      "OK              676\n",
      "AR              564\n",
      "UT              556\n",
      "NM              424\n",
      "HI              423\n",
      "MS              370\n",
      "NH              365\n",
      "WV              344\n",
      "RI              337\n",
      "MT              225\n",
      "DC              206\n",
      "DE              205\n",
      "AK              198\n",
      "WY              167\n",
      "SD              162\n",
      "VT              155\n",
      "NE              120\n",
      "ND               45\n",
      "ME               44\n",
      "Name: State, dtype: int64\n",
      "debt  consolidation    46471\n",
      "credit  card           18626\n",
      "home  improvement       4326\n",
      "other                   3366\n",
      "major  purchase         1338\n",
      "medical                  717\n",
      "small  business          675\n",
      "car                      622\n",
      "moving                   446\n",
      "vacation                 367\n",
      "house                    290\n",
      "wedding                   96\n",
      "RENTwable  energy         36\n",
      "Name: Reason, dtype: int64\n",
      "2    22020\n",
      "3    21817\n",
      "1    12582\n",
      "4    12254\n",
      "5     6319\n",
      "6     1950\n",
      "7      434\n",
      "Name: GGGrade, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Ver qual as variáveis ordinais mais dominantes\n",
    "for i in v_cat_ord:\n",
    "    print(df[i].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77376, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(74132, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remover outliers\n",
    "from scipy import stats\n",
    "display(df.shape)\n",
    "#Remove \"other\" and \"none\"\n",
    "df=df[(df['Home_Status']!='OTHER')&(df['Home_Status']!='NONE')]\n",
    "#Tirar a médias e divide pelo desvio padrão\n",
    "df=df[(np.abs(stats.zscore(df[v_num_cont])) < 3).all(axis=1)]\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14126"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Número de default positivos\n",
    "(df['Default']==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10000, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Undersapling\n",
    "defaulted = df[df['Default']==1].sample(n=5000, random_state=101)\n",
    "notdefault = df[df['Default']==0].sample(n=5000, random_state=101)\n",
    "df = pd.concat([defaulted,notdefault],axis=0)\n",
    "df.shape\n",
    "df = df.reset_index()\n",
    "display(df.index)\n",
    "#aplicar undersampling com sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs test sample: standard and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index: [0 1 2 3 4 5 6 8 9] Test index: [7]\n",
      "Train index: [0 1 2 3 4 5 7 8 9] Test index: [6]\n",
      "Train index: [0 2 3 4 5 6 7 8 9] Test index: [1]\n",
      "Train index: [0 1 2 3 4 5 6 7 9] Test index: [8]\n",
      "Train index: [0 1 3 4 5 6 7 8 9] Test index: [2]\n",
      "Train index: [1 2 3 4 5 6 7 8 9] Test index: [0]\n",
      "Train index: [0 1 2 3 4 6 7 8 9] Test index: [5]\n",
      "Train index: [0 1 2 4 5 6 7 8 9] Test index: [3]\n",
      "Train index: [0 1 2 3 5 6 7 8 9] Test index: [4]\n",
      "Train index: [0 1 2 3 4 5 6 7 8] Test index: [9]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "X = df[v_num_cont]\n",
    "y = df['Default']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#implement cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "kfold = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    print(\"Train index:\", train_index, \"Test index:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>15.38</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>42.65</td>\n",
       "      <td>25.65</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-7.74</td>\n",
       "      <td>38.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>49.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_value</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Asst_Reg  Experience  Yearly_Income  Lend_Amount  Interest_Charged  \\\n",
       "skewness     15.38        -7.9          42.65        25.65             -0.48   \n",
       "p_value       0.00         0.0           0.00         0.00              0.63   \n",
       "\n",
       "          Usage_Rate  Present_Balance  Due_Fee  Unpaid_Amount  \n",
       "skewness       -7.74            38.59     1.00          49.36  \n",
       "p_value         0.00             0.00     0.32           0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Asst_Reg', 'Experience', 'Yearly_Income', 'Lend_Amount', 'Usage_Rate',\n",
       "       'Present_Balance', 'Unpaid_Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make the input data as \"normal\" as possible\n",
    "#start by decreasing the skewness and assessing which are asymmetric\n",
    "def skew_df(df):\n",
    "    from scipy.stats import skewtest\n",
    "    skewness, p_value = skewtest(df)\n",
    "    dskew=pd.DataFrame(np.round(np.vstack((skewness.T,p_value.T)),2),columns=df.columns,\n",
    "                    index=['skewness', 'p_value'])\n",
    "    return(dskew)\n",
    "\n",
    "#aplica esta métricas às variáveis continuas\n",
    "\n",
    "dskew=skew_df(df[v_num_cont])\n",
    "display(dskew)\n",
    "\n",
    "#Treshoold 0.5\n",
    "dskew.columns[dskew.loc['p_value']<0.05]\n",
    "#quando mais o p_value for próximo de 0 mais assimétrico é\n",
    "Transformação para as transforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Due_Fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>1.333455</td>\n",
       "      <td>1.084212</td>\n",
       "      <td>0.734597</td>\n",
       "      <td>1.185273</td>\n",
       "      <td>0.487517</td>\n",
       "      <td>0.553462</td>\n",
       "      <td>1.792878</td>\n",
       "      <td>19.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>-1.173896</td>\n",
       "      <td>0.050424</td>\n",
       "      <td>-0.320546</td>\n",
       "      <td>-1.311223</td>\n",
       "      <td>-0.492565</td>\n",
       "      <td>-1.191977</td>\n",
       "      <td>-1.060496</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>-1.143481</td>\n",
       "      <td>-0.519924</td>\n",
       "      <td>-0.903321</td>\n",
       "      <td>-0.558293</td>\n",
       "      <td>-0.501115</td>\n",
       "      <td>-0.536214</td>\n",
       "      <td>-0.207936</td>\n",
       "      <td>21.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>1.146308</td>\n",
       "      <td>1.084212</td>\n",
       "      <td>-0.360919</td>\n",
       "      <td>0.662361</td>\n",
       "      <td>-1.578597</td>\n",
       "      <td>-0.774602</td>\n",
       "      <td>-0.064845</td>\n",
       "      <td>20.43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>1.406309</td>\n",
       "      <td>1.084212</td>\n",
       "      <td>-1.836748</td>\n",
       "      <td>-1.283128</td>\n",
       "      <td>-1.385828</td>\n",
       "      <td>-1.138176</td>\n",
       "      <td>-1.674696</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>1.149179</td>\n",
       "      <td>0.320072</td>\n",
       "      <td>1.054637</td>\n",
       "      <td>1.274243</td>\n",
       "      <td>-1.333479</td>\n",
       "      <td>1.098302</td>\n",
       "      <td>0.877176</td>\n",
       "      <td>22.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.968053</td>\n",
       "      <td>-0.228886</td>\n",
       "      <td>-0.529100</td>\n",
       "      <td>-0.402970</td>\n",
       "      <td>-1.866332</td>\n",
       "      <td>-0.833991</td>\n",
       "      <td>-1.824126</td>\n",
       "      <td>18.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1.204036</td>\n",
       "      <td>-0.825722</td>\n",
       "      <td>-0.054328</td>\n",
       "      <td>-0.186242</td>\n",
       "      <td>-0.969226</td>\n",
       "      <td>-1.279444</td>\n",
       "      <td>-0.312175</td>\n",
       "      <td>9.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.657779</td>\n",
       "      <td>-1.151117</td>\n",
       "      <td>-1.533211</td>\n",
       "      <td>-0.402970</td>\n",
       "      <td>0.115725</td>\n",
       "      <td>-0.727794</td>\n",
       "      <td>0.347738</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.699878</td>\n",
       "      <td>1.084212</td>\n",
       "      <td>1.350567</td>\n",
       "      <td>0.805689</td>\n",
       "      <td>1.543936</td>\n",
       "      <td>0.060035</td>\n",
       "      <td>2.083031</td>\n",
       "      <td>11.43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Asst_Reg  Experience  Yearly_Income  Lend_Amount  Usage_Rate  \\\n",
       "9254  1.333455    1.084212       0.734597     1.185273    0.487517   \n",
       "1561 -1.173896    0.050424      -0.320546    -1.311223   -0.492565   \n",
       "1670 -1.143481   -0.519924      -0.903321    -0.558293   -0.501115   \n",
       "6087  1.146308    1.084212      -0.360919     0.662361   -1.578597   \n",
       "6669  1.406309    1.084212      -1.836748    -1.283128   -1.385828   \n",
       "...        ...         ...            ...          ...         ...   \n",
       "5734  1.149179    0.320072       1.054637     1.274243   -1.333479   \n",
       "5191  0.968053   -0.228886      -0.529100    -0.402970   -1.866332   \n",
       "5390  1.204036   -0.825722      -0.054328    -0.186242   -0.969226   \n",
       "860   0.657779   -1.151117      -1.533211    -0.402970    0.115725   \n",
       "7270  0.699878    1.084212       1.350567     0.805689    1.543936   \n",
       "\n",
       "      Present_Balance  Unpaid_Amount  Interest_Charged  Due_Fee  \n",
       "9254         0.553462       1.792878             19.39      0.0  \n",
       "1561        -1.191977      -1.060496             24.24      0.0  \n",
       "1670        -0.536214      -0.207936             21.72      0.0  \n",
       "6087        -0.774602      -0.064845             20.43      0.0  \n",
       "6669        -1.138176      -1.674696             20.85      0.0  \n",
       "...               ...            ...               ...      ...  \n",
       "5734         1.098302       0.877176             22.38      0.0  \n",
       "5191        -0.833991      -1.824126             18.97      0.0  \n",
       "5390        -1.279444      -0.312175              9.53      0.0  \n",
       "860         -0.727794       0.347738              8.15      0.0  \n",
       "7270         0.060035       2.083031             11.43      0.0  \n",
       "\n",
       "[8000 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Define the transformations to apply to the column\n",
    "transformer = ColumnTransformer([\n",
    "    #('scale', PowerTransformer(), ['col1']),  # Scale the numeric column\n",
    "    ('yeoj', PowerTransformer(), dskew.columns[dskew.loc['p_value']<0.05])  # One-hot encode the column\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "df_transformed = transformer.fit_transform(X_train)\n",
    "#display(X_train)\n",
    "X_train_transformed= pd.concat([pd.DataFrame(df_transformed,\n",
    "                                  columns=dskew.columns[dskew.loc['p_value']<0.05],index=X_train.index),\n",
    "                               X_train[dskew.columns[dskew.loc['p_value']>=0.05]]],\n",
    "                               axis=1)\n",
    "#display(X_train[dskew.columns[dskew.loc['p_value']>=0.05]])\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.001}\n",
      "Best score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       988\n",
      "           1       0.74      0.71      0.73      1012\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.73      0.73      0.73      2000\n",
      "weighted avg       0.73      0.73      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "#print(accuracy_score(y_test,y_pred))\n",
    "#print(precision_score(y_test,y_pred))\n",
    "#print(recall_score(y_test,y_pred))\n",
    "#print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[739 249]\n",
      " [290 722]]\n",
      "0.7307072218399449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "# Generate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7305\n",
      "0.7435633367662204\n",
      "0.7134387351778656\n",
      "0.7281896116994453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the data\n",
    "X_transformed = df[v_num_cont].copy()\n",
    "\n",
    "# Logarithmize variables with skewness greater than a threshold\n",
    "for i in range(0,len(X_transformed.columns)):\n",
    "    if (dskew.loc['p_value'])[i] < 0.05:\n",
    "        print(i)\n",
    "    #   X_transformed.iloc[:, i] = (X_transformed.iloc[:, i]).apply(np.log)\n",
    "\n",
    "#log_skewed(df[v_num_cont],dskew,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import yeojohnson\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "yeojohnson(X_transformed.iloc[:, 1])\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "pipe=Pipeline([\n",
    "    #('yeoj',PowerTransformer()),\n",
    "    ('ratio', FunctionTransformer(yeojohnson, validate=False, kw_args={'columns': [0, 1]}))\n",
    "    #('zscore',StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "yeojohnson() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:434\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    432\u001b[0m fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit_transform(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\u001b[38;5;241m.\u001b[39mtransform(Xt)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:182\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    181\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:205\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[1;34m(self, X, func, kw_args)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     func \u001b[38;5;241m=\u001b[39m _identity\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kw_args \u001b[38;5;28;01mif\u001b[39;00m kw_args \u001b[38;5;28;01melse\u001b[39;00m {}))\n",
      "\u001b[1;31mTypeError\u001b[0m: yeojohnson() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skew' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compute the skewness of the feature variables\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m skewness \u001b[38;5;241m=\u001b[39m \u001b[43mskew\u001b[49m(X)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a function to logarithmize variables with statistically significant skewness\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogarithmize_skewed_variables\u001b[39m(X):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Create a copy of the data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skew' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute the skewness of the feature variables\n",
    "skewness = skew(X)\n",
    "\n",
    "# Create a function to logarithmize variables with statistically significant skewness\n",
    "def logarithmize_skewed_variables(X):\n",
    "    # Create a copy of the data\n",
    "    X_transformed = X.copy()\n",
    "\n",
    "    # Logarithmize variables with skewness greater than a threshold\n",
    "    threshold = 1.0\n",
    "    for i, s in enumerate(skewness):\n",
    "        if np.abs(s) > threshold:\n",
    "            X_transformed[:, i] = np.log1p(X_transformed[:, i])\n",
    "\n",
    "    return X_transformed\n",
    "\n",
    "# Create a function transformer to logarithmize variables with statistically significant skewness\n",
    "logarithmize_transformer = FunctionTransformer(logarithmize_skewed_variables, validate=True)\n",
    "\n",
    "# Create a feature selector to select the top k features\n",
    "k = 10\n",
    "feature_selector = SelectKBest(k=k)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('logarithmize', logarithmize_transformer),\n",
    "    ('select_features', feature_selector)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2038413857.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [48]\u001b[1;36m\u001b[0m\n\u001b[1;33m    ('standardize', StandardScaler())\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "# Create a function that returns the ratio of the specified columns\n",
    "def get_ratio(x, columns):\n",
    "    return x[:, columns[0]] / x[:, columns[1]]\n",
    "# Create a function that returns the log of the input if it is positive, or the input itself otherwise\n",
    "def log_positive(x):\n",
    "    return np.log(x) if x > 0 else x\n",
    "# Create a pipeline that first logarithmizes the specified columns, then standardizes the data\n",
    "pipeline = Pipeline([\n",
    "    ('ratio', FunctionTransformer(get_ratio, validate=False, kw_args={'columns': [0, 1]})),\n",
    "    ('log', FunctionTransformer(log_positive, validate=False, kw_args={'columns': [0, 1]}))\n",
    "]),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Apply the pipeline to the data\n",
    "X_transformed = pipeline.fit_transform(X)\n",
    "\n",
    "# Print the transformed data\n",
    "print(X_transformed)\n",
    "\n",
    "#This code will create a pipeline that first applies the log_positive function to the specified columns, and then standardizes the data using the StandardScaler class. It will then apply the pipeline to the data X and print the transformed data to the console.\n",
    "\n",
    "#You can use a different set of transformations in place of logarithmization and standardization, as needed. You can also specify the columns to be transformed by passing the columns parameter to the FunctionTransformer constructor, or you can use a different transformer class to apply a different set of transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Use Recursive Feature Elimination (RFE) to select the top 2 features\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m rfe \u001b[38;5;241m=\u001b[39m \u001b[43mRFE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m rfe\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Transform the training and test data using the selected features\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) to select the top 2 features\n",
    "rfe = RFE(model, 2)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and test data using the selected features\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Train the model on the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the selected features of the test data\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "############################################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be an empty list\n",
    "selected_features = []\n",
    "\n",
    "# Set the maximum number of features to select\n",
    "max_features = 2\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "for i in range(1, len(feature_indices) + 1):\n",
    "    for combination in combinations(feature_indices, i):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, combination]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            selected_features = combination\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)\n",
    "##########################################\n",
    "#BACKWARD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be all the features\n",
    "selected_features = feature_indices\n",
    "\n",
    "# Set the minimum number of features to select\n",
    "min_features = 1\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "while len(selected_features) > min_features:\n",
    "    scores = []\n",
    "    for i in range(len(selected_features)):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, selected_features]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # Add the score for the current combination of features\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Find the index of the feature with the lowest score\n",
    "    worst_feature_index = np.argmin(scores)\n",
    "    \n",
    "    # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "    if scores[worst_feature_index] > best_score:\n",
    "        best_score = scores[worst_feature_index]\n",
    "        selected_features = selected_features[:worst_feature_index] + selected_features[worst_feature_index + 1:]\n",
    "    else:\n",
    "        # If the current combination of features has a lower cross-validated score than the best score, stop the search\n",
    "        break\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.00\n",
      "DecisionTreeClassifier: 0.00\n",
      "RandomForestClassifier: 0.00\n",
      "SVC: 0.00\n",
      "MLPClassifier: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\familia feliz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit different models and evaluate their performance\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"{model.__class__.__name__}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StackingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m meta_model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Define the stacking model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m stacking_model \u001b[38;5;241m=\u001b[39m \u001b[43mStackingClassifier\u001b[49m(estimators\u001b[38;5;241m=\u001b[39mbase_models, final_estimator\u001b[38;5;241m=\u001b[39mmeta_model, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Fit the stacking model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m stacking_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StackingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#STACKING\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "# Define the second-level model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Define the stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = stacking_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (3957181239.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [54]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "  \n",
    "pca = PCA(n_components = 2)\n",
    "  \n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "  \n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#xgboost\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create the XGBoost model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING AS PREPROCESSING DATA INTO CLASSIFICATION PROBLEM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use KMeans to cluster the training data into 3 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the training data\n",
    "X_train_clustered = np.concatenate((X_train, kmeans.labels_.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Create a Random Forest classifier and train it on the clustered data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_clustered, y_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the test data\n",
    "X_test_clustered = np.concatenate((X_test, kmeans.predict(X_test).reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to pick the optimal number of clusters for a clustering algorithm is to use an evaluation metric that compares the quality of different clusterings. There are many such metrics available, such as the silhouette score, the Calinski-Harabasz index, and the Davies-Bouldin index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '’' (U+2019) (2572941075.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [58]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Let’s look at the best value for k and the performance of the resulting pipeline:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '’' (U+2019)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Try clustering the data with different numbers of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.predict(X)\n",
    "\n",
    "    # Calculate the silhouette score for this number of clusters\n",
    "    score = silhouette_score(X, cluster_labels)\n",
    "    print(\"Number of clusters:\", n_clusters, \"Silhouette score:\", score)\n",
    "    \n",
    "    ###################\n",
    "#PROF DOC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "(\"kmeans\", KMeans(n_clusters=50)),\n",
    "(\"log_reg\", LogisticRegression()),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "Let’s look at the best value for k and the performance of the resulting pipeline:\n",
    ">>> grid_clf.best_params_\n",
    "{'kmeans__n_clusters': 99}\n",
    ">>> grid_clf.score(X_test, y_test)\n",
    "0.9822222222222222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Create a PCA object and fit it to the data\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "# Plot the explained variance ratio as a function of the number of dimensions\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of dimensions')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimal number of dimensions based on the explained variance ratio\n",
    "n_dimensions = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "\n",
    "# Transform the training and test data using the chosen number of dimensions\n",
    "X_train_transformed = pca.transform(X_train)[:, :n_dimensions]\n",
    "X_test_transformed = pca.transform(X_test)[:, :n_dimensions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different types of clustering algorithms, but some of the most common ones include:\n",
    "\n",
    "    K-means clustering: This is a centroid-based algorithm that divides a dataset into a predefined number of clusters by minimizing the sum of squared distances between the points and the cluster centroids.\n",
    "\n",
    "    Hierarchical clustering: This is an agglomerative algorithm that builds a hierarchy of clusters by iteratively merging the closest pairs of clusters.\n",
    "\n",
    "    DBSCAN: This is a density-based algorithm that divides a dataset into clusters based on the density of the points. It is able to identify clusters of different shapes and sizes and can handle noisy or outlier points.\n",
    "\n",
    "    Expectation-maximization (EM): This is a probabilistic algorithm that estimates the underlying distribution of the data and uses it to identify clusters.\n",
    "\n",
    "    Affinity propagation: This is a message-passing algorithm that identifies clusters by exchanging messages between pairs of points until a consensus is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Libraries used\n",
    "#%load utilities\n",
    "import utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "df = pd.read_csv('loan_default_prediction.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop\n",
    "vdrop=['ID','Validation','Designation','Debt_to_Income','Postal_Code','Deprecatory_Records',\\\n",
    "            'Inquiries','Gross_Collection','Sub_GGGrade','Total_Unpaid_CL','File_Status','Claim_Type','Due_Fee']\n",
    "df=df.drop(vdrop,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversão dos anos de experiência para numérico\n",
    "df['Experience']=df['Experience'].apply(lambda i: 10 if i[0:1]=='>' else 1 if i[0:1]=='<' else int(i[0:1]))\n",
    "#Conversão da duração para numérico\n",
    "df['Duration']=df['Duration'].apply(lambda i : i.replace(' years','years')).astype(str)\n",
    "#Conversão da GGGrade valor ordinal para numérico\n",
    "df['GGGrade']=df['GGGrade'].apply(romanToInt).astype(int)\n",
    "#criacao de debt to income\n",
    "#calcular o total da divida e o rendimento anual. uma espécie de \"taxa de esforço\"\n",
    "df['debt_to_income']=df['Unpaid_Amount']/df['Yearly_Income']\n",
    "#ver resultado\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar observações com pelo menos uma feature sem valores\n",
    "df=df.dropna()\n",
    "#drop duplicates\n",
    "df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num_cont=['Asst_Reg','Experience','Yearly_Income','Lend_Amount','Interest_Charged','Usage_Rate',\n",
    "            'Present_Balance','Unpaid_Amount','debt_to_income']\n",
    "v_num_disc=['Unpaid_2_years','Already_Defaulted','Account_Open']\n",
    "v_cat_ord=['Home_Status','State','Reason','Duration']#,'GGGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fazer histograma das categoricas e value_counts (verificar se há categorias de pouca relevancia)\n",
    "for i in v_cat_ord:\n",
    "    print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "display(df.shape)\n",
    "#remover observações com home status 'none' e 'other'\n",
    "df=df[(df['Home_Status']!='OTHER')&(df['Home_Status']!='NONE')]\n",
    "#remover linhas com outliers, definidos como mais que 3 desvios-padrão acima/abaixo da média\n",
    "df=df[(np.abs(stats.zscore(df[v_num_cont])) < 3).all(axis=1)]\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver quantas observações têm default=1\n",
    "display((df['Default']==1).sum())\n",
    "#sample de 5000 obs com default =1\n",
    "defaulted = df[df['Default']==1].sample(n=5000, random_state=101)\n",
    "#sample de 5000 obs com default =0\n",
    "notdefault = df[df['Default']==0].sample(n=5000, random_state=101)\n",
    "#agregar as observações\n",
    "df = pd.concat([defaulted,notdefault],axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort aleatório das obs\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "#display(df.head(10))\n",
    "#display(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[v_num_disc].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer histograma das categoricas e value_counts (verificar se há categorias de pouca relevancia)\n",
    "for i in v_cat_ord:\n",
    "    print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs test sample: standard and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "#QUANDO PIPELINE ESTIVER PARA TODAS AS VARIÁVEIS, MUDAR O X\n",
    "X = df[v_num_cont]\n",
    "X = df[v_num_cont+v_num_disc+v_cat_ord]\n",
    "y = df['Default']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#script não ativado para fazer cross validation manual (normalmente o scikit learn faz tudo automático)\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = KFold(n_splits=5,shuffle=True)\n",
    "#for train_index, test_index in kfold.split(X):\n",
    "#    print(\"Train index:\", train_index, \"Test index:\", test_index)\n",
    "#    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "#    y_train, y_test = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a parte: tentar reduzir assimetria das variáveis\n",
    "\n",
    "#criar função que devolve uma métrica de assimetria das variáveis e avalia se essa variável\n",
    "#está suficientemente distante de 0 para ter certeza que é assimétrica\n",
    "#como se vê isso? quanto mais pequeno for o p-value (2a linha dataframe), mais certezas temos que é assimétrica\n",
    "\n",
    "#verificar assimetria das features numéricas\n",
    "dskew=skew_df(X_train[v_num_cont+v_num_disc])\n",
    "#mostrar output\n",
    "display(dskew)\n",
    "#ver lista de features assimétricas, pvalue < 5%\n",
    "v_skew=list(dskew.columns[dskew.loc['p_value']<0.05])\n",
    "#lista de simétricas são as restantes\n",
    "v_sym=list(set(X_train[v_num_cont+v_num_disc].columns) - set(v_skew))\n",
    "#check\n",
    "v_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the transformations to apply to the column\n",
    "transformer = ColumnTransformer([\n",
    "    ('yeoj', PowerTransformer(), v_skew), #aplico transformação que corrige assimetria às assimétricas\n",
    "    ('std', StandardScaler(), v_sym),     #aplico transformação às simétricas (sub média e dividir desvio padrao)7\n",
    "    ('oneh', OneHotEncoder(min_frequency=0.05,handle_unknown='ignore',#drop='if_biNameErrorary',\n",
    "                           sparse_output=False), v_cat_ord)\n",
    "])\n",
    "\n",
    "#pipeline= Pipeline([\n",
    "    #('ct', transformer),\n",
    "    #('to_df', pd.DataFrame, {'columns': v_skew+v_sym})\n",
    "    #(\"pandarizer\",FunctionTransformer(lambda x: pd.DataFrame(x, columns = (v_skew + v_sym))))\n",
    "#])\n",
    "\n",
    "# Transform the data\n",
    "pfit = transformer.fit(X_train)\n",
    "\n",
    "categories= pfit.transformers_[2][1].categories_\n",
    "categories_out=pfit.transformers_[2][1].infrequent_categories_\n",
    "\n",
    "v_onehot_drop=list(np.concatenate([np.concatenate([categories[i][np.isin(categories[i], categories_out[i], invert=True)]],axis=0) \n",
    "                        for i in range(0,len(categories))],axis=0))\n",
    "\n",
    "\n",
    "v_onehot=list(np.concatenate([(np.concatenate((np.array(j),\n",
    "                       (np.array(['Other_Cat'+str(k)]) if categories_out[k] is not None else np.array([]))),axis=0)) \n",
    "                         for k,j in enumerate(\n",
    "                         [np.concatenate([categories[i][np.isin(categories[i], categories_out[i], invert=True)]],axis=0) \n",
    "                        for i in range(0,len(categories))]\n",
    "                         )]))\n",
    "\n",
    "X_train_transf = transformer.transform(X_train)\n",
    "X_train_transf = pd.DataFrame(transformer.transform(X_train),columns = (v_skew + v_sym+v_onehot)\n",
    "                              ,index=X_train.index)\n",
    "\n",
    "#aplicar transformações ao teste calcula\n",
    "X_test_transf = transformer.transform(X_test)\n",
    "X_test_transf = pd.DataFrame(transformer.transform(X_test),columns = (v_skew + v_sym+v_onehot)\n",
    "                            ,index=X_test.index)\n",
    "\n",
    "display(round(X_train_transf.describe(),2))\n",
    "#vamos dar um check se o dataframe ficou \"menos assimétrico\"\n",
    "skew_df(X_train_transf[v_skew+v_sym])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer histograma das categoricas e value_counts (verificar se há categorias de pouca relevancia)\n",
    "cc=[]\n",
    "for i in v_cat_ord:\n",
    "    c=df[i].value_counts()/df.shape[0]\n",
    "    list(c[c>.05].index)\n",
    "    print(list(c[c>.05].index))\n",
    "    #cc=cc+c\n",
    "    \n",
    "cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection/Unsupervise Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA to the training data to reduce the dimensionality\n",
    "#ALWAYS STANDARDIZE\n",
    "#VER SE VALE A PENA FAZER UNS GRAFICOS\n",
    "#POR EXEMPLO\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=0.9999)\n",
    "\n",
    "X_pca=pca.fit(X_train_transf[v_skew+v_sym])\n",
    "# Determine explained variance using explained_variance_ration_ attribute\n",
    "#\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "#\n",
    "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "# for visualizing the variance explained by each principal component.\n",
    "#\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "# Create the visualization plot\n",
    "#\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.80)\n",
    "\n",
    "X_pca=pca.fit(X_train_transf[v_skew+v_sym])\n",
    "\n",
    "X_train_pca=pd.DataFrame(pca.transform(X_train_transf[v_skew+v_sym]),\n",
    "                         columns=['pca_v'+str(i+1) for i in range (0,X_pca.n_components_)],\n",
    "                        index=X_train_transf.index)\n",
    "\n",
    "X_test_pca=pd.DataFrame(pca.transform(X_test_transf[v_skew+v_sym]),\n",
    "                         columns=['pca_v'+str(i+1) for i in range (0,X_pca.n_components_)],\n",
    "                        index=X_test_transf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_pca=pd.concat([X_train_pca,pd.DataFrame(y_train)],axis=1)\n",
    "#display(df_pca.head(5))\n",
    "\n",
    "sns.scatterplot(x='pca_v1', y='pca_v2', hue='Default', data=df_pca);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_pca.corr()\n",
    "display(round(corr.iloc[[-1],:],2))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,cmap=\"BuPu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#############\n",
    "pipeline = Pipeline([\n",
    "(\"kmeans\", KMeans(n_clusters=10)),\n",
    "(\"log_reg\", LogisticRegression()),\n",
    "])\n",
    "#pipeline.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 50))\n",
    "display(param_grid)\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=5)#, score='f1')\n",
    "grid_clf.fit(X_train_transf, y_train)\n",
    "\n",
    "display(grid_clf.best_params_)\n",
    "\n",
    "#grid_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid_clf.best_params_)\n",
    "\n",
    "grid_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Apply K-means clustering to the training data\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "X_train_clusters = kmeans.fit_predict(X_train_transf)\n",
    "X_test_clusters = kmeans.predict(X_test_transf)\n",
    "\n",
    "# Create the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_clusters.reshape(-1, 1), y_train)\n",
    "\n",
    "########################################\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Set up the cross-validation and grid search\n",
    "kfold = KFold(n_splits=5)\n",
    "param_grid = {'n_clusters': [2, 3, 4, 5, 6]}\n",
    "model = KMeans()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "# Run the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Re-train the model on the entire dataset with the best parameters\n",
    "model = KMeans(**grid_search.best_params_)\n",
    "X_clusters = model.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_transf, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LinearSVC(loss='hinge',max_iter=10000)\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_transf, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf=DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X_train_transf,y_train)\n",
    "y_pred=tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(tree_clf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "est=KBinsDiscretizer(n_bins=5,encode='ordinal',strategy='uniform')\n",
    "est.fit(X_train)\n",
    "Xt_train=est.transform(X_train_transf)\n",
    "Xt_test=est.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnNB=MultinomialNB()\n",
    "mnNB.fit(Xt_train,y_train)\n",
    "y_pred=mnNB.predict(Xt_test)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gNB=MultinomialNB()\n",
    "gNB.fit(X_train_transf,y_train)\n",
    "y_pred=gNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_Model=RandomForestClassifier()\n",
    "rf_Model.fit(X_train_transf,y_train)\n",
    "y_pred=rf_Model.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trees\n",
    "n_estimators=[int(x) for x in np.linspace(10,100,4)]\n",
    "#number of splits to consider at every split\n",
    "max_features=['auto','sqrt']\n",
    "#maximum number of levels\n",
    "max_depth=[2,4]\n",
    "#min of samples required to split a node\n",
    "min_samples_split=[2,5]\n",
    "#min samples required at each leaf node\n",
    "min_samples_leaf=[1,2]\n",
    "#method of selecting samples for training each tree\n",
    "bootstrap=[True,False]\n",
    "\n",
    "param_grid={'n_estimators':n_estimators,\n",
    "            'max_features':max_features,\n",
    "            'max_depth':max_depth,\n",
    "            'min_samples_split':min_samples_split,\n",
    "            'min_samples_leaf':min_samples_leaf,\n",
    "            'bootstrap':bootstrap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_Grid=GridSearchCV(rf_Model,param_grid,cv=5)\n",
    "rf_Grid.fit(X_train_transf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=rf_Grid.predict(X_test)\n",
    "rf_Grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred=knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# Define the parameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'max_depth': 5,  # maximum depth of the tree\n",
    "    'learning_rate': 0.1,  # learning rate\n",
    "    'n_estimators': 100  # number of trees to be built\n",
    "}\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier(**params)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_transf, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test_transf)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))\n",
    "##########################\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the data\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Set up the cross-validation and grid search\n",
    "kfold = KFold(n_splits=5)\n",
    "param_grid = {'learning_rate': [0.1, 0.2, 0.3],\n",
    "              'max_depth': [3, 4, 5],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "model = XGBClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "# Run the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Re-train the model on the entire dataset with the best parameters\n",
    "model = XGBClassifier(**grid_search.best_params_)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the test data\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "##################################################### Set up the cross-validation and grid search\n",
    "kfold = KFold(n_splits=5)\n",
    "param_grid = {'hidden_layer_sizes': [(10,), (20,), (30,), (40,)],\n",
    "              'solver': ['adam', 'sgd'],\n",
    "              'activation': ['relu', 'tanh']}\n",
    "model = MLPClassifier(max_iter=1000)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "# Run the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Re-train the model on the entire dataset with the best parameters\n",
    "model = MLPClassifier(max_iter=1000, **grid_search.best_params_)\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "###########################################################\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the data\n",
    "X, y = load_data()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(X_train.shape[1],), activation='relu'),  # hidden layer\n",
    "    tf.keras.layers.Dense(y_train_one_hot.shape[1], activation='softmax')  # output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_one_hot, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred_one_hot = model.predict(X_test)\n",
    "\n",
    "# Convert the one-hot encoding back to labels\n",
    "y_pred = np.argmax(y_pred_one_hot, axis=1)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinação de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOTING\n",
    "\n",
    "#sklearn.ensemble.VotingClassifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit different models and evaluate their performance\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"{model.__class__.__name__}: {accuracy:.2f}\")\n",
    "    \n",
    "    #STACKING\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "# Define the second-level model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Define the stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = stacking_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "#print(accuracy_score(y_test,y_pred))\n",
    "#print(precision_score(y_test,y_pred))\n",
    "#print(recall_score(y_test,y_pred))\n",
    "#print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "# Generate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred)\n",
    "    \n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) to select the top 2 features\n",
    "rfe = RFE(model, 2)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and test data using the selected features\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Train the model on the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the selected features of the test data\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "############################################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be an empty list\n",
    "selected_features = []\n",
    "\n",
    "# Set the maximum number of features to select\n",
    "max_features = 2\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "for i in range(1, len(feature_indices) + 1):\n",
    "    for combination in combinations(feature_indices, i):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, combination]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            selected_features = combination\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)\n",
    "##########################################\n",
    "#BACKWARD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be all the features\n",
    "selected_features = feature_indices\n",
    "\n",
    "# Set the minimum number of features to select\n",
    "min_features = 1\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "while len(selected_features) > min_features:\n",
    "    scores = []\n",
    "    for i in range(len(selected_features)):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, selected_features]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # Add the score for the current combination of features\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Find the index of the feature with the lowest score\n",
    "    worst_feature_index = np.argmin(scores)\n",
    "    \n",
    "    # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "    if scores[worst_feature_index] > best_score:\n",
    "        best_score = scores[worst_feature_index]\n",
    "        selected_features = selected_features[:worst_feature_index] + selected_features[worst_feature_index + 1:]\n",
    "    else:\n",
    "        # If the current combination of features has a lower cross-validated score than the best score, stop the search\n",
    "        break\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING AS PREPROCESSING DATA INTO CLASSIFICATION PROBLEM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use KMeans to cluster the training data into 3 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the training data\n",
    "X_train_clustered = np.concatenate((X_train, kmeans.labels_.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Create a Random Forest classifier and train it on the clustered data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_clustered, y_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the test data\n",
    "X_test_clustered = np.concatenate((X_test, kmeans.predict(X_test).reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to pick the optimal number of clusters for a clustering algorithm is to use an evaluation metric that compares the quality of different clusterings. There are many such metrics available, such as the silhouette score, the Calinski-Harabasz index, and the Davies-Bouldin index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "# Try clustering the data with different numbers of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.predict(X)\n",
    "\n",
    "    # Calculate the silhouette score for this number of clusters\n",
    "    score = silhouette_score(X, cluster_labels)\n",
    "    print(\"Number of clusters:\", n_clusters, \"Silhouette score:\", score)\n",
    "    \n",
    "    ###################\n",
    "#PROF DOC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "(\"kmeans\", KMeans(n_clusters=50)),\n",
    "(\"log_reg\", LogisticRegression()),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "Let’s look at the best value for k and the performance of the resulting pipeline:\n",
    ">>> grid_clf.best_params_\n",
    "{'kmeans__n_clusters': 99}\n",
    ">>> grid_clf.score(X_test, y_test)\n",
    "0.9822222222222222"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

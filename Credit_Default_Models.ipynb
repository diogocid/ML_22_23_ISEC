{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Libraries used\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas._libs.testing as _testing\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87500, 30)\n"
     ]
    }
   ],
   "source": [
    "#Import Dataset\n",
    "df = pd.read_csv('loan_default_prediction.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87500, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop\n",
    "vdrop=['ID','Validation','Designation','Debt_to_Income','Postal_Code','Deprecatory_Records',\\\n",
    "            'Inquiries','Gross_Collection','Sub_GGGrade','Total_Unpaid_CL','File_Status','Claim_Type']\n",
    "df=df.drop(vdrop,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def romanToInt(i):\n",
    "    roman = {'I':1,'V':5,'X':10,'L':50,'C':100,'D':500,'M':1000,'IV':4,'IX':9,'XL':40,'XC':90,'CD':400,'CM':900}\n",
    "    j = 0\n",
    "    num = 0\n",
    "    while j < len(i):\n",
    "        if j+1<len(i) and i[j:j+2] in roman:\n",
    "            num+=roman[i[j:j+2]]\n",
    "            j+=2\n",
    "        else:\n",
    "\n",
    "            num+=roman[i[j]]\n",
    "            j+=1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversão dos anos de experiência para numérico\n",
    "df['Experience']=df['Experience'].apply(lambda i: 10 if i[0:1]=='>' else 1 if i[0:1]=='<' else int(i[0:1]))\n",
    "#Conversão da duração para numérico\n",
    "df['Duration']=df['Duration'].apply(lambda i : i.replace(' years','')).astype(int)\n",
    "#Conversão da GGGrade valor ordinal para numérico\n",
    "df['GGGrade']=df['GGGrade'].apply(romanToInt).astype(int)\n",
    "#ver resultado\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77376, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar observações com pelo menos uma feature sem valores\n",
    "df=df.dropna()\n",
    "#drop duplicates\n",
    "df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>GGGrade</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Home_Status</th>\n",
       "      <th>Unpaid_2_years</th>\n",
       "      <th>Already_Defaulted</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>State</th>\n",
       "      <th>Account_Open</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421802</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>633600.00</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42023.25</td>\n",
       "      <td>15.39</td>\n",
       "      <td>88.924</td>\n",
       "      <td>607161.90</td>\n",
       "      <td>California</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>31216.05</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3964312</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>85483.20</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38133.00</td>\n",
       "      <td>9.94</td>\n",
       "      <td>102.856</td>\n",
       "      <td>269234.06</td>\n",
       "      <td>NC</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11660.49</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4247560</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>79200.00</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17100.00</td>\n",
       "      <td>22.35</td>\n",
       "      <td>60.372</td>\n",
       "      <td>22476.53</td>\n",
       "      <td>Florida</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5637.87</td>\n",
       "      <td>major  purchase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197179</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61600.00</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5130.00</td>\n",
       "      <td>10.36</td>\n",
       "      <td>116.272</td>\n",
       "      <td>15242.09</td>\n",
       "      <td>NewJersey</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>15607.17</td>\n",
       "      <td>major  purchase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646684</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>68053.92</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19665.00</td>\n",
       "      <td>13.68</td>\n",
       "      <td>127.280</td>\n",
       "      <td>65433.94</td>\n",
       "      <td>LA</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>27472.86</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asst_Reg  GGGrade  Experience  Yearly_Income Home_Status  Unpaid_2_years  \\\n",
       "0    421802        2          10      633600.00    MORTGAGE               0   \n",
       "1   3964312        4           7       85483.20        RENT               0   \n",
       "2   4247560        3           1       79200.00        RENT               0   \n",
       "3    197179        3           1       61600.00        RENT               0   \n",
       "4   4646684        5           2       68053.92        RENT               0   \n",
       "\n",
       "   Already_Defaulted  Lend_Amount  Interest_Charged  Usage_Rate  \\\n",
       "0                  0     42023.25             15.39      88.924   \n",
       "1                  0     38133.00              9.94     102.856   \n",
       "2                  0     17100.00             22.35      60.372   \n",
       "3                  0      5130.00             10.36     116.272   \n",
       "4                  0     19665.00             13.68     127.280   \n",
       "\n",
       "   Present_Balance       State  Account_Open  Duration  Unpaid_Amount  \\\n",
       "0        607161.90  California            17         3       31216.05   \n",
       "1        269234.06          NC            15         5       11660.49   \n",
       "2         22476.53     Florida             7         5        5637.87   \n",
       "3         15242.09   NewJersey             9         3       15607.17   \n",
       "4         65433.94          LA            10         5       27472.86   \n",
       "\n",
       "                Reason  Due_Fee  Default  \n",
       "0  debt  consolidation      0.0        0  \n",
       "1  debt  consolidation      0.0        0  \n",
       "2      major  purchase      0.0        0  \n",
       "3      major  purchase      0.0        1  \n",
       "4  debt  consolidation      0.0        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.describe()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num_cont=['Asst_Reg','Experience','Yearly_Income','Lend_Amount','Interest_Charged','Usage_Rate',\n",
    "            'Present_Balance','Due_Fee','Unpaid_Amount']\n",
    "v_num_disc=['Unpaid_2_years','Already_Defaulted','Account_Open','Duration']\n",
    "v_cat_ord=['Home_Status','State','Reason','GGGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MORTGAGE    39077\n",
      "RENT        30853\n",
      "OWN          7436\n",
      "OTHER           6\n",
      "NONE            4\n",
      "Name: Home_Status, dtype: int64\n",
      "California    11194\n",
      "Newyork        6414\n",
      "TX             6307\n",
      "Florida        5149\n",
      "IL             3091\n",
      "NewJersey      2877\n",
      "PA             2797\n",
      "Ohio           2602\n",
      "GA             2572\n",
      "VA             2251\n",
      "NC             2230\n",
      "MI             1995\n",
      "Maryland       1857\n",
      "AZ             1797\n",
      "MA             1764\n",
      "CO             1685\n",
      "WA             1627\n",
      "MN             1493\n",
      "IN             1276\n",
      "MO             1253\n",
      "TN             1184\n",
      "CT             1172\n",
      "NV             1039\n",
      "AL              999\n",
      "WI              990\n",
      "OR              929\n",
      "LA              908\n",
      "SC              888\n",
      "KY              728\n",
      "KS              722\n",
      "OK              676\n",
      "AR              564\n",
      "UT              556\n",
      "NM              424\n",
      "HI              423\n",
      "MS              370\n",
      "NH              365\n",
      "WV              344\n",
      "RI              337\n",
      "MT              225\n",
      "DC              206\n",
      "DE              205\n",
      "AK              198\n",
      "WY              167\n",
      "SD              162\n",
      "VT              155\n",
      "NE              120\n",
      "ND               45\n",
      "ME               44\n",
      "Name: State, dtype: int64\n",
      "debt  consolidation    46471\n",
      "credit  card           18626\n",
      "home  improvement       4326\n",
      "other                   3366\n",
      "major  purchase         1338\n",
      "medical                  717\n",
      "small  business          675\n",
      "car                      622\n",
      "moving                   446\n",
      "vacation                 367\n",
      "house                    290\n",
      "wedding                   96\n",
      "RENTwable  energy         36\n",
      "Name: Reason, dtype: int64\n",
      "2    22020\n",
      "3    21817\n",
      "1    12582\n",
      "4    12254\n",
      "5     6319\n",
      "6     1950\n",
      "7      434\n",
      "Name: GGGrade, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#fazer histograma das categoricas e value_counts (verificar se há categorias de pouca relevancia)\n",
    "for i in v_cat_ord:\n",
    "    print(df[i].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'int' from 'numpy' (/home/goncalo/anaconda3/lib/python3.8/site-packages/numpy/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4468814f4ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Home_Status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'OTHER'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Home_Status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'NONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_num_cont\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \"\"\"\n\u001b[0;32m--> 388\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmeasurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m from scipy._lib._util import (_lazywhere, check_random_state, MapWrapper,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/spatial/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_plotutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_procrustes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocrustes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_geometric_slerp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeometric_slerp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/spatial/_geometric_slerp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_hausdorff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrel_entr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/special/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ufuncs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_basic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/special/_basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                       poch, binom, hyp0f1)\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspecfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0morthogonal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_comb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_comb_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/special/orthogonal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# SciPy imports.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n\u001b[0m\u001b[1;32m     80\u001b[0m                    hstack, arccos, arange)\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'int' from 'numpy' (/home/goncalo/anaconda3/lib/python3.8/site-packages/numpy/__init__.py)"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "display(df.shape)\n",
    "df=df[(df['Home_Status']!='OTHER')&(df['Home_Status']!='NONE')]\n",
    "df=df[(np.abs(stats.zscore(df[v_num_cont])) < 3).all(axis=1)]\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14629"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Default']==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10000, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "defaulted = df[df['Default']==1].sample(n=5000, random_state=101)\n",
    "notdefault = df[df['Default']==0].sample(n=5000, random_state=101)\n",
    "df = pd.concat([defaulted,notdefault],axis=0)\n",
    "df.shape\n",
    "df = df.reset_index()\n",
    "display(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs test sample: standard and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "X = df[v_num_cont]\n",
    "y = df['Default']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#implement cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = KFold(n_splits=5,shuffle=True)\n",
    "#for train_index, test_index in kfold.split(X):\n",
    "#    print(\"Train index:\", train_index, \"Test index:\", test_index)\n",
    "#    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "#    y_train, y_test = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>15.38</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>42.65</td>\n",
       "      <td>25.65</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-7.74</td>\n",
       "      <td>38.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>49.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_value</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Asst_Reg  Experience  Yearly_Income  Lend_Amount  Interest_Charged  \\\n",
       "skewness     15.38        -7.9          42.65        25.65             -0.48   \n",
       "p_value       0.00         0.0           0.00         0.00              0.63   \n",
       "\n",
       "          Usage_Rate  Present_Balance  Due_Fee  Unpaid_Amount  \n",
       "skewness       -7.74            38.59     1.00          49.36  \n",
       "p_value         0.00             0.00     0.32           0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make the input data as \"normal\" as possible\n",
    "#start by decreasing the skewness and assessing which are asymmetric\n",
    "def skew_df(df):\n",
    "    from scipy.stats import skewtest\n",
    "    skewness, p_value = skewtest(df)\n",
    "    dskew=pd.DataFrame(np.round(np.vstack((skewness.T,p_value.T)),2),columns=df.columns,\n",
    "                    index=['skewness', 'p_value'])\n",
    "    return(dskew)\n",
    "\n",
    "dskew=skew_df(df[v_num_cont])\n",
    "display(dskew)\n",
    "v_skew=list(dskew.columns[dskew.loc['p_value']<0.05])\n",
    "v_sym=list(set(X_train.columns) - set(v_skew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Interest_Charged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.973717</td>\n",
       "      <td>1.064834</td>\n",
       "      <td>0.300292</td>\n",
       "      <td>-0.575944</td>\n",
       "      <td>1.584279</td>\n",
       "      <td>-1.348118</td>\n",
       "      <td>0.085311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.256935</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>1.402172</td>\n",
       "      <td>1.222470</td>\n",
       "      <td>-1.584856</td>\n",
       "      <td>1.251379</td>\n",
       "      <td>-0.350859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.362923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.911331</td>\n",
       "      <td>0.286656</td>\n",
       "      <td>1.086286</td>\n",
       "      <td>0.765449</td>\n",
       "      <td>-0.828236</td>\n",
       "      <td>2.003421</td>\n",
       "      <td>0.852903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.438995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asst_Reg  Experience  Yearly_Income  Lend_Amount  Usage_Rate  \\\n",
       "0 -0.973717    1.064834       0.300292    -0.575944    1.584279   \n",
       "1 -0.256935    0.014724       1.402172     1.222470   -1.584856   \n",
       "2 -0.911331    0.286656       1.086286     0.765449   -0.828236   \n",
       "\n",
       "   Present_Balance  Unpaid_Amount  Due_Fee  Interest_Charged  \n",
       "0        -1.348118       0.085311      0.0         -0.950017  \n",
       "1         1.251379      -0.350859      0.0         -1.362923  \n",
       "2         2.003421       0.852903      0.0         -0.438995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Interest_Charged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.397869</td>\n",
       "      <td>1.064834</td>\n",
       "      <td>0.644443</td>\n",
       "      <td>1.627011</td>\n",
       "      <td>0.729540</td>\n",
       "      <td>1.255159</td>\n",
       "      <td>1.146483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.012306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.456915</td>\n",
       "      <td>-1.514876</td>\n",
       "      <td>0.832043</td>\n",
       "      <td>0.278993</td>\n",
       "      <td>-1.576200</td>\n",
       "      <td>0.907219</td>\n",
       "      <td>-1.456315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.030845</td>\n",
       "      <td>-0.554921</td>\n",
       "      <td>0.809456</td>\n",
       "      <td>-0.575944</td>\n",
       "      <td>1.205803</td>\n",
       "      <td>-0.740800</td>\n",
       "      <td>-0.746265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asst_Reg  Experience  Yearly_Income  Lend_Amount  Usage_Rate  \\\n",
       "0  1.397869    1.064834       0.644443     1.627011    0.729540   \n",
       "1 -0.456915   -1.514876       0.832043     0.278993   -1.576200   \n",
       "2 -1.030845   -0.554921       0.809456    -0.575944    1.205803   \n",
       "\n",
       "   Present_Balance  Unpaid_Amount  Due_Fee  Interest_Charged  \n",
       "0         1.255159       1.146483      0.0          1.012306  \n",
       "1         0.907219      -1.456315      0.0          1.527416  \n",
       "2        -0.740800      -0.746265      0.0          0.863088  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the transformations to apply to the column\n",
    "transformer = ColumnTransformer([\n",
    "    #('scale', PowerTransformer(), ['col1']),  # Scale the numeric column\n",
    "    ('yeoj', PowerTransformer(), v_skew),\n",
    "    ('std', StandardScaler(), v_sym)\n",
    "])\n",
    "\n",
    "pipeline= Pipeline([\n",
    "    ('ct', transformer),\n",
    "    #('to_df', pd.DataFrame, {'columns': v_skew+v_sym})\n",
    "    (\"pandarizer\",FunctionTransformer(lambda x: pd.DataFrame(x, columns = (v_skew + v_sym))))\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "pfit = pipeline.fit(X_train)\n",
    "X_train_transf = pipeline.transform(X_train)\n",
    "X_test_transf = pipeline.transform(X_test)\n",
    "\n",
    "#display(X_train)\n",
    "#print((v_skew+v_sym))\n",
    "#X_train_transformed= pd.DataFrame(df_transformed,\n",
    "                                 # columns=(v_skew+v_sym),index=X_train.index)\n",
    "#X_train_transformed.describe()\n",
    "display(X_train_transf.head(3))\n",
    "display(X_test_transf.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.001}\n",
      "Best score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_transf, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10}\n",
      "Best score: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/goncalo/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LinearSVC(loss='hinge')\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_transf, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf=DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X_train_transf,y_train)\n",
    "y_pred=tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(tree_clf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "est=KBinsDiscretizer(n_bins=5,encode='ordinal',strategy='uniform')\n",
    "est.fit(X_train)\n",
    "Xt_train=est.transform(X_train_transf)\n",
    "Xt_test=est.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnNB=MultinomialNB()\n",
    "mnNB.fit(Xt_train,y_train)\n",
    "y_pred=mnNB.predict(Xt_test)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gNB=MultinomialNB()\n",
    "gNB.fit(X_train_transf,y_train)\n",
    "y_pred=gNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_Model=RandomForestClassifier()\n",
    "rf_Model.fit(X_train_transf,y_train)\n",
    "y_pred=rf_Model.predict(X_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trees\n",
    "n_estimators=[int(x) for x in np.linspace(10,100,4)]\n",
    "#number of splits to consider at every split\n",
    "max_features=['auto','sqrt']\n",
    "#maximum number of levels\n",
    "max_depth=[2,4]\n",
    "#min of samples required to split a node\n",
    "min_samples_split=[2,5]\n",
    "#min samples required at each leaf node\n",
    "min_samples_leaf=[1,2]\n",
    "#method of selecting samples for training each tree\n",
    "bootstrap=[True,False]\n",
    "\n",
    "param_grid={'n_estimators':n_estimators,\n",
    "            'max_features':max_features,\n",
    "            'max_depth':max_depth,\n",
    "            'min_samples_split':min_samples_split,\n",
    "            'min_samples_leaf':min_samples_leaf,\n",
    "            'bootstrap':bootstrap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [2, 4],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [10, 40, 70, 100]})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_Grid=GridSearchCV(rf_Model,param_grid,cv=5)\n",
    "rf_Grid.fit(X_train_transf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73475"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred=rf_Grid.predict(X_test)\n",
    "rf_Grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred=knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       988\n",
      "           1       0.71      0.78      0.74      1012\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.73      0.73      0.73      2000\n",
      "weighted avg       0.73      0.73      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# Define the parameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'max_depth': 5,  # maximum depth of the tree\n",
    "    'learning_rate': 0.1,  # learning rate\n",
    "    'n_estimators': 100  # number of trees to be built\n",
    "}\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier(**params)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_transf, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test_transf)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.2-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 193.6 MB 94 kB/s  eta 0:00:012  |▏                               | 1.0 MB 1.8 MB/s eta 0:01:50     |█▊                              | 10.2 MB 5.3 MB/s eta 0:00:35     |█▉                              | 11.0 MB 1.7 MB/s eta 0:01:47     |███████                         | 43.0 MB 4.6 MB/s eta 0:00:34     |██████████████████████████▌     | 160.1 MB 1.8 MB/s eta 0:00:19     |███████████████████████████▊    | 167.6 MB 129 kB/s eta 0:03:21\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/goncalo/anaconda3/lib/python3.8/site-packages (from xgboost) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/goncalo/anaconda3/lib/python3.8/site-packages (from xgboost) (1.18.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the data\n",
    "X, y = load_data()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(X_train.shape[1],), activation='relu'),  # hidden layer\n",
    "    tf.keras.layers.Dense(y_train_one_hot.shape[1], activation='softmax')  # output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_one_hot, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred_one_hot = model.predict(X_test)\n",
    "\n",
    "# Convert the one-hot encoding back to labels\n",
    "y_pred = np.argmax(y_pred_one_hot, axis=1)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       988\n",
      "           1       0.71      0.76      0.74      1012\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.72      0.72      0.72      2000\n",
      "weighted avg       0.72      0.72      0.72      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "#print(accuracy_score(y_test,y_pred))\n",
    "#print(precision_score(y_test,y_pred))\n",
    "#print(recall_score(y_test,y_pred))\n",
    "#print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[736 252]\n",
      " [299 713]]\n",
      "0.7247423629002575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "# Generate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7315\n",
      "0.734915924826904\n",
      "0.7341897233201581\n",
      "0.7345526445872467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred)\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.plot([0,1],[0,1],'r')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC - TPR vs FPR')\n",
    "    \n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) to select the top 2 features\n",
    "rfe = RFE(model, 2)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and test data using the selected features\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Train the model on the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the selected features of the test data\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "############################################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be an empty list\n",
    "selected_features = []\n",
    "\n",
    "# Set the maximum number of features to select\n",
    "max_features = 2\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "for i in range(1, len(feature_indices) + 1):\n",
    "    for combination in combinations(feature_indices, i):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, combination]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            selected_features = combination\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)\n",
    "##########################################\n",
    "#BACKWARD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be all the features\n",
    "selected_features = feature_indices\n",
    "\n",
    "# Set the minimum number of features to select\n",
    "min_features = 1\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "while len(selected_features) > min_features:\n",
    "    scores = []\n",
    "    for i in range(len(selected_features)):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, selected_features]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # Add the score for the current combination of features\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Find the index of the feature with the lowest score\n",
    "    worst_feature_index = np.argmin(scores)\n",
    "    \n",
    "    # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "    if scores[worst_feature_index] > best_score:\n",
    "        best_score = scores[worst_feature_index]\n",
    "        selected_features = selected_features[:worst_feature_index] + selected_features[worst_feature_index + 1:]\n",
    "    else:\n",
    "        # If the current combination of features has a lower cross-validated score than the best score, stop the search\n",
    "        break\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-be82a844217a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Standardize the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dd40e4e7e366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit different models and evaluate their performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m models = [\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit different models and evaluate their performance\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"{model.__class__.__name__}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STACKING\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "# Define the second-level model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Define the stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = stacking_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "  \n",
    "pca = PCA(n_components = 2)\n",
    "  \n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "  \n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index: [0 1 2 3 4 6 7 9] Test index: [5 8]\n",
      "Train index: [0 1 2 3 4 5 6 8] Test index: [7 9]\n",
      "Train index: [0 2 4 5 6 7 8 9] Test index: [1 3]\n",
      "Train index: [1 3 4 5 6 7 8 9] Test index: [0 2]\n",
      "Train index: [0 1 2 3 5 7 8 9] Test index: [4 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING AS PREPROCESSING DATA INTO CLASSIFICATION PROBLEM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use KMeans to cluster the training data into 3 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the training data\n",
    "X_train_clustered = np.concatenate((X_train, kmeans.labels_.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Create a Random Forest classifier and train it on the clustered data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_clustered, y_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the test data\n",
    "X_test_clustered = np.concatenate((X_test, kmeans.predict(X_test).reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to pick the optimal number of clusters for a clustering algorithm is to use an evaluation metric that compares the quality of different clusterings. There are many such metrics available, such as the silhouette score, the Calinski-Harabasz index, and the Davies-Bouldin index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Try clustering the data with different numbers of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.predict(X)\n",
    "\n",
    "    # Calculate the silhouette score for this number of clusters\n",
    "    score = silhouette_score(X, cluster_labels)\n",
    "    print(\"Number of clusters:\", n_clusters, \"Silhouette score:\", score)\n",
    "    \n",
    "    ###################\n",
    "#PROF DOC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "(\"kmeans\", KMeans(n_clusters=50)),\n",
    "(\"log_reg\", LogisticRegression()),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "Let’s look at the best value for k and the performance of the resulting pipeline:\n",
    ">>> grid_clf.best_params_\n",
    "{'kmeans__n_clusters': 99}\n",
    ">>> grid_clf.score(X_test, y_test)\n",
    "0.9822222222222222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Create a PCA object and fit it to the data\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "# Plot the explained variance ratio as a function of the number of dimensions\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of dimensions')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-66b1c0fdbc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Choose the optimal number of dimensions based on the explained variance ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Transform the training and test data using the chosen number of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pca' is not defined"
     ]
    }
   ],
   "source": [
    "# Choose the optimal number of dimensions based on the explained variance ratio\n",
    "n_dimensions = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "\n",
    "# Transform the training and test data using the chosen number of dimensions\n",
    "X_train_transformed = pca.transform(X_train)[:, :n_dimensions]\n",
    "X_test_transformed = pca.transform(X_test)[:, :n_dimensions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different types of clustering algorithms, but some of the most common ones include:\n",
    "\n",
    "    K-means clustering: This is a centroid-based algorithm that divides a dataset into a predefined number of clusters by minimizing the sum of squared distances between the points and the cluster centroids.\n",
    "\n",
    "    Hierarchical clustering: This is an agglomerative algorithm that builds a hierarchy of clusters by iteratively merging the closest pairs of clusters.\n",
    "\n",
    "    DBSCAN: This is a density-based algorithm that divides a dataset into clusters based on the density of the points. It is able to identify clusters of different shapes and sizes and can handle noisy or outlier points.\n",
    "\n",
    "    Expectation-maximization (EM): This is a probabilistic algorithm that estimates the underlying distribution of the data and uses it to identify clusters.\n",
    "\n",
    "    Affinity propagation: This is a message-passing algorithm that identifies clusters by exchanging messages between pairs of points until a consensus is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Libraries used\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87500, 30)\n"
     ]
    }
   ],
   "source": [
    "#Import Dataset\n",
    "df = pd.read_csv('loan_default_prediction.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87500, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop\n",
    "vdrop=['ID','Validation','Designation','Debt_to_Income','Postal_Code','Deprecatory_Records',\\\n",
    "            'Inquiries','Gross_Collection','Sub_GGGrade','Total_Unpaid_CL','File_Status','Claim_Type']\n",
    "df=df.drop(vdrop,axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def romanToInt(i):\n",
    "    roman = {'I':1,'V':5,'X':10,'L':50,'C':100,'D':500,'M':1000,'IV':4,'IX':9,'XL':40,'XC':90,'CD':400,'CM':900}\n",
    "    j = 0\n",
    "    num = 0\n",
    "    while j < len(i):\n",
    "        if j+1<len(i) and i[j:j+2] in roman:\n",
    "            num+=roman[i[j:j+2]]\n",
    "            j+=2\n",
    "        else:\n",
    "\n",
    "            num+=roman[i[j]]\n",
    "            j+=1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversão dos anos de experiência para numérico\n",
    "df['Experience']=df['Experience'].apply(lambda i: 10 if i[0:1]=='>' else 1 if i[0:1]=='<' else int(i[0:1]))\n",
    "#Conversão da duração para numérico\n",
    "df['Duration']=df['Duration'].apply(lambda i : i.replace(' years','')).astype(int)\n",
    "#Conversão da GGGrade valor ordinal para numérico\n",
    "df['GGGrade']=df['GGGrade'].apply(romanToInt).astype(int)\n",
    "#ver resultado\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77376, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar observações com pelo menos uma feature sem valores\n",
    "df=df.dropna()\n",
    "#drop duplicates\n",
    "df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>GGGrade</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Home_Status</th>\n",
       "      <th>Unpaid_2_years</th>\n",
       "      <th>Already_Defaulted</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>State</th>\n",
       "      <th>Account_Open</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421802</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>633600.00</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42023.25</td>\n",
       "      <td>15.39</td>\n",
       "      <td>88.924</td>\n",
       "      <td>607161.90</td>\n",
       "      <td>California</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>31216.05</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3964312</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>85483.20</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38133.00</td>\n",
       "      <td>9.94</td>\n",
       "      <td>102.856</td>\n",
       "      <td>269234.06</td>\n",
       "      <td>NC</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11660.49</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4247560</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>79200.00</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17100.00</td>\n",
       "      <td>22.35</td>\n",
       "      <td>60.372</td>\n",
       "      <td>22476.53</td>\n",
       "      <td>Florida</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5637.87</td>\n",
       "      <td>major  purchase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197179</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61600.00</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5130.00</td>\n",
       "      <td>10.36</td>\n",
       "      <td>116.272</td>\n",
       "      <td>15242.09</td>\n",
       "      <td>NewJersey</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>15607.17</td>\n",
       "      <td>major  purchase</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646684</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>68053.92</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19665.00</td>\n",
       "      <td>13.68</td>\n",
       "      <td>127.280</td>\n",
       "      <td>65433.94</td>\n",
       "      <td>LA</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>27472.86</td>\n",
       "      <td>debt  consolidation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asst_Reg  GGGrade  Experience  Yearly_Income Home_Status  Unpaid_2_years  \\\n",
       "0    421802        2          10      633600.00    MORTGAGE               0   \n",
       "1   3964312        4           7       85483.20        RENT               0   \n",
       "2   4247560        3           1       79200.00        RENT               0   \n",
       "3    197179        3           1       61600.00        RENT               0   \n",
       "4   4646684        5           2       68053.92        RENT               0   \n",
       "\n",
       "   Already_Defaulted  Lend_Amount  Interest_Charged  Usage_Rate  \\\n",
       "0                  0     42023.25             15.39      88.924   \n",
       "1                  0     38133.00              9.94     102.856   \n",
       "2                  0     17100.00             22.35      60.372   \n",
       "3                  0      5130.00             10.36     116.272   \n",
       "4                  0     19665.00             13.68     127.280   \n",
       "\n",
       "   Present_Balance       State  Account_Open  Duration  Unpaid_Amount  \\\n",
       "0        607161.90  California            17         3       31216.05   \n",
       "1        269234.06          NC            15         5       11660.49   \n",
       "2         22476.53     Florida             7         5        5637.87   \n",
       "3         15242.09   NewJersey             9         3       15607.17   \n",
       "4         65433.94          LA            10         5       27472.86   \n",
       "\n",
       "                Reason  Due_Fee  Default  \n",
       "0  debt  consolidation      0.0        0  \n",
       "1  debt  consolidation      0.0        0  \n",
       "2      major  purchase      0.0        0  \n",
       "3      major  purchase      0.0        1  \n",
       "4  debt  consolidation      0.0        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.describe()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num_cont=['Asst_Reg','Experience','Yearly_Income','Lend_Amount','Interest_Charged','Usage_Rate',\n",
    "            'Present_Balance','Due_Fee','Unpaid_Amount']\n",
    "v_num_disc=['Unpaid_2_years','Already_Defaulted','Account_Open','Duration']\n",
    "v_cat_ord=['Home_Status','State','Reason','GGGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MORTGAGE    39077\n",
      "RENT        30853\n",
      "OWN          7436\n",
      "OTHER           6\n",
      "NONE            4\n",
      "Name: Home_Status, dtype: int64\n",
      "California    11194\n",
      "Newyork        6414\n",
      "TX             6307\n",
      "Florida        5149\n",
      "IL             3091\n",
      "NewJersey      2877\n",
      "PA             2797\n",
      "Ohio           2602\n",
      "GA             2572\n",
      "VA             2251\n",
      "NC             2230\n",
      "MI             1995\n",
      "Maryland       1857\n",
      "AZ             1797\n",
      "MA             1764\n",
      "CO             1685\n",
      "WA             1627\n",
      "MN             1493\n",
      "IN             1276\n",
      "MO             1253\n",
      "TN             1184\n",
      "CT             1172\n",
      "NV             1039\n",
      "AL              999\n",
      "WI              990\n",
      "OR              929\n",
      "LA              908\n",
      "SC              888\n",
      "KY              728\n",
      "KS              722\n",
      "OK              676\n",
      "AR              564\n",
      "UT              556\n",
      "NM              424\n",
      "HI              423\n",
      "MS              370\n",
      "NH              365\n",
      "WV              344\n",
      "RI              337\n",
      "MT              225\n",
      "DC              206\n",
      "DE              205\n",
      "AK              198\n",
      "WY              167\n",
      "SD              162\n",
      "VT              155\n",
      "NE              120\n",
      "ND               45\n",
      "ME               44\n",
      "Name: State, dtype: int64\n",
      "debt  consolidation    46471\n",
      "credit  card           18626\n",
      "home  improvement       4326\n",
      "other                   3366\n",
      "major  purchase         1338\n",
      "medical                  717\n",
      "small  business          675\n",
      "car                      622\n",
      "moving                   446\n",
      "vacation                 367\n",
      "house                    290\n",
      "wedding                   96\n",
      "RENTwable  energy         36\n",
      "Name: Reason, dtype: int64\n",
      "2    22020\n",
      "3    21817\n",
      "1    12582\n",
      "4    12254\n",
      "5     6319\n",
      "6     1950\n",
      "7      434\n",
      "Name: GGGrade, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#fazer histograma das categoricas e value_counts (verificar se há categorias de pouca relevancia)\n",
    "for i in v_cat_ord:\n",
    "    print(df[i].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe\n",
    "#describe(df[vnumcont], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77376, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(74132, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "display(df.shape)\n",
    "df=df[(df['Home_Status']!='OTHER')&(df['Home_Status']!='NONE')]\n",
    "df=df[(np.abs(stats.zscore(df[v_num_cont])) < 3).all(axis=1)]\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Default']==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10000, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "defaulted = df[df['Default']==1].sample(n=5000, random_state=101)\n",
    "notdefault = df[df['Default']==0].sample(n=5000, random_state=101)\n",
    "df = pd.concat([defaulted,notdefault],axis=0)\n",
    "df.shape\n",
    "df = df.reset_index()\n",
    "display(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs test sample: standard and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "X = df[v_num_cont]\n",
    "y = df['Default']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#implement cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "#X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20]])\n",
    "#y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "#kfold = KFold(n_splits=5,shuffle=True)\n",
    "#for train_index, test_index in kfold.split(X):\n",
    "#    print(\"Train index:\", train_index, \"Test index:\", test_index)\n",
    "#    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "#    y_train, y_test = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>Due_Fee</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>15.38</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>42.65</td>\n",
       "      <td>25.65</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-7.74</td>\n",
       "      <td>38.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>49.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_value</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Asst_Reg  Experience  Yearly_Income  Lend_Amount  Interest_Charged  \\\n",
       "skewness     15.38        -7.9          42.65        25.65             -0.48   \n",
       "p_value       0.00         0.0           0.00         0.00              0.63   \n",
       "\n",
       "          Usage_Rate  Present_Balance  Due_Fee  Unpaid_Amount  \n",
       "skewness       -7.74            38.59     1.00          49.36  \n",
       "p_value         0.00             0.00     0.32           0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Asst_Reg', 'Experience', 'Yearly_Income', 'Lend_Amount', 'Usage_Rate',\n",
       "       'Present_Balance', 'Unpaid_Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make the input data as \"normal\" as possible\n",
    "#start by decreasing the skewness and assessing which are asymmetric\n",
    "def skew_df(df):\n",
    "    from scipy.stats import skewtest\n",
    "    skewness, p_value = skewtest(df)\n",
    "    dskew=pd.DataFrame(np.round(np.vstack((skewness.T,p_value.T)),2),columns=df.columns,\n",
    "                    index=['skewness', 'p_value'])\n",
    "    return(dskew)\n",
    "\n",
    "dskew=skew_df(df[v_num_cont])\n",
    "display(dskew)\n",
    "dskew.columns[dskew.loc['p_value']<0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asst_Reg</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Yearly_Income</th>\n",
       "      <th>Lend_Amount</th>\n",
       "      <th>Usage_Rate</th>\n",
       "      <th>Present_Balance</th>\n",
       "      <th>Unpaid_Amount</th>\n",
       "      <th>Interest_Charged</th>\n",
       "      <th>Due_Fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>-0.973717</td>\n",
       "      <td>1.064834</td>\n",
       "      <td>0.300292</td>\n",
       "      <td>-0.575944</td>\n",
       "      <td>1.584279</td>\n",
       "      <td>-1.348118</td>\n",
       "      <td>0.085311</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>-0.256935</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>1.402172</td>\n",
       "      <td>1.222470</td>\n",
       "      <td>-1.584856</td>\n",
       "      <td>1.251379</td>\n",
       "      <td>-0.350859</td>\n",
       "      <td>9.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>-0.911331</td>\n",
       "      <td>0.286656</td>\n",
       "      <td>1.086286</td>\n",
       "      <td>0.765449</td>\n",
       "      <td>-0.828236</td>\n",
       "      <td>2.003421</td>\n",
       "      <td>0.852903</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>1.413336</td>\n",
       "      <td>-1.514876</td>\n",
       "      <td>0.394585</td>\n",
       "      <td>1.627011</td>\n",
       "      <td>-0.892391</td>\n",
       "      <td>0.462947</td>\n",
       "      <td>-0.165308</td>\n",
       "      <td>21.37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>0.502100</td>\n",
       "      <td>1.064834</td>\n",
       "      <td>0.941596</td>\n",
       "      <td>1.992554</td>\n",
       "      <td>-1.115209</td>\n",
       "      <td>0.084569</td>\n",
       "      <td>1.687238</td>\n",
       "      <td>13.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>1.056274</td>\n",
       "      <td>-1.174406</td>\n",
       "      <td>-0.307983</td>\n",
       "      <td>0.842884</td>\n",
       "      <td>-0.201852</td>\n",
       "      <td>-0.359393</td>\n",
       "      <td>1.104976</td>\n",
       "      <td>16.76</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>1.449919</td>\n",
       "      <td>-0.265249</td>\n",
       "      <td>-1.522892</td>\n",
       "      <td>-0.740345</td>\n",
       "      <td>1.319421</td>\n",
       "      <td>-0.880022</td>\n",
       "      <td>-0.948355</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.713497</td>\n",
       "      <td>1.064834</td>\n",
       "      <td>0.151947</td>\n",
       "      <td>-0.074807</td>\n",
       "      <td>-1.196799</td>\n",
       "      <td>1.157319</td>\n",
       "      <td>-0.279704</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-1.244143</td>\n",
       "      <td>-1.174406</td>\n",
       "      <td>-0.942753</td>\n",
       "      <td>-1.566994</td>\n",
       "      <td>-0.320871</td>\n",
       "      <td>0.903022</td>\n",
       "      <td>-1.610398</td>\n",
       "      <td>13.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>-1.051576</td>\n",
       "      <td>-0.554921</td>\n",
       "      <td>-0.330067</td>\n",
       "      <td>-0.818389</td>\n",
       "      <td>-0.342138</td>\n",
       "      <td>-1.989664</td>\n",
       "      <td>-1.137927</td>\n",
       "      <td>19.96</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Asst_Reg  Experience  Yearly_Income  Lend_Amount  Usage_Rate  \\\n",
       "9254 -0.973717    1.064834       0.300292    -0.575944    1.584279   \n",
       "1561 -0.256935    0.014724       1.402172     1.222470   -1.584856   \n",
       "1670 -0.911331    0.286656       1.086286     0.765449   -0.828236   \n",
       "6087  1.413336   -1.514876       0.394585     1.627011   -0.892391   \n",
       "6669  0.502100    1.064834       0.941596     1.992554   -1.115209   \n",
       "...        ...         ...            ...          ...         ...   \n",
       "5734  1.056274   -1.174406      -0.307983     0.842884   -0.201852   \n",
       "5191  1.449919   -0.265249      -1.522892    -0.740345    1.319421   \n",
       "5390  0.713497    1.064834       0.151947    -0.074807   -1.196799   \n",
       "860  -1.244143   -1.174406      -0.942753    -1.566994   -0.320871   \n",
       "7270 -1.051576   -0.554921      -0.330067    -0.818389   -0.342138   \n",
       "\n",
       "      Present_Balance  Unpaid_Amount  Interest_Charged  Due_Fee  \n",
       "9254        -1.348118       0.085311             12.00      0.0  \n",
       "1561         1.251379      -0.350859              9.98      0.0  \n",
       "1670         2.003421       0.852903             14.50      0.0  \n",
       "6087         0.462947      -0.165308             21.37      0.0  \n",
       "6669         0.084569       1.687238             13.71      0.0  \n",
       "...               ...            ...               ...      ...  \n",
       "5734        -0.359393       1.104976             16.76      0.0  \n",
       "5191        -0.880022      -0.948355             12.67      0.0  \n",
       "5390         1.157319      -0.279704             19.87      0.0  \n",
       "860          0.903022      -1.610398             13.97      0.0  \n",
       "7270        -1.989664      -1.137927             19.96      0.0  \n",
       "\n",
       "[8000 rows x 9 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Define the transformations to apply to the column\n",
    "transformer = ColumnTransformer([\n",
    "    #('scale', PowerTransformer(), ['col1']),  # Scale the numeric column\n",
    "    ('yeoj', PowerTransformer(), dskew.columns[dskew.loc['p_value']<0.05])  # One-hot encode the column\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "df_transformed = transformer.fit_transform(X_train)\n",
    "#display(X_train)\n",
    "X_train_transformed= pd.concat([pd.DataFrame(df_transformed,\n",
    "                                  columns=dskew.columns[dskew.loc['p_value']<0.05],index=X_train.index),\n",
    "                               X_train[dskew.columns[dskew.loc['p_value']>=0.05]]],\n",
    "                               axis=1)\n",
    "#display(X_train[dskew.columns[dskew.loc['p_value']>=0.05]])\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.001}\n",
      "Best score: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       988\n",
      "           1       0.74      0.70      0.72      1012\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.72      0.72      0.72      2000\n",
      "weighted avg       0.73      0.72      0.72      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "#print(accuracy_score(y_test,y_pred))\n",
    "#print(precision_score(y_test,y_pred))\n",
    "#print(recall_score(y_test,y_pred))\n",
    "#print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[736 252]\n",
      " [299 713]]\n",
      "0.7247423629002575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(roc_auc)\n",
    "\n",
    "# Generate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7245\n",
      "0.738860103626943\n",
      "0.7045454545454546\n",
      "0.7212948912493677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the data\n",
    "X_transformed = df[v_num_cont].copy()\n",
    "\n",
    "# Logarithmize variables with skewness greater than a threshold\n",
    "for i in range(0,len(X_transformed.columns)):\n",
    "    if (dskew.loc['p_value'])[i] < 0.05:\n",
    "        print(i)\n",
    "    #   X_transformed.iloc[:, i] = (X_transformed.iloc[:, i]).apply(np.log)\n",
    "\n",
    "#log_skewed(df[v_num_cont],dskew,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import yeojohnson\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "yeojohnson(X_transformed.iloc[:, 1])\n",
    "pt = PowerTransformer()\n",
    "\n",
    "pipe=Pipeline([\n",
    "    #('yeoj',PowerTransformer()),\n",
    "    ('ratio', FunctionTransformer(yeojohnson, validate=False, kw_args={'columns': [0, 1]}))\n",
    "    #('zscore',StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "yeojohnson() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-5a2be7b3ed68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 return last_step.fit(Xt, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_args\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkw_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: yeojohnson() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the skewness of the feature variables\n",
    "skewness = skew(X)\n",
    "\n",
    "# Create a function to logarithmize variables with statistically significant skewness\n",
    "def logarithmize_skewed_variables(X):\n",
    "    # Create a copy of the data\n",
    "    X_transformed = X.copy()\n",
    "\n",
    "    # Logarithmize variables with skewness greater than a threshold\n",
    "    threshold = 1.0\n",
    "    for i, s in enumerate(skewness):\n",
    "        if np.abs(s) > threshold:\n",
    "            X_transformed[:, i] = np.log1p(X_transformed[:, i])\n",
    "\n",
    "    return X_transformed\n",
    "\n",
    "# Create a function transformer to logarithmize variables with statistically significant skewness\n",
    "logarithmize_transformer = FunctionTransformer(logarithmize_skewed_variables, validate=True)\n",
    "\n",
    "# Create a feature selector to select the top k features\n",
    "k = 10\n",
    "feature_selector = SelectKBest(k=k)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('logarithmize', logarithmize_transformer),\n",
    "    ('select_features', feature_selector)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "# Create a function that returns the ratio of the specified columns\n",
    "def get_ratio(x, columns):\n",
    "    return x[:, columns[0]] / x[:, columns[1]]\n",
    "# Create a function that returns the log of the input if it is positive, or the input itself otherwise\n",
    "def log_positive(x):\n",
    "    return np.log(x) if x > 0 else x\n",
    "# Create a pipeline that first logarithmizes the specified columns, then standardizes the data\n",
    "pipeline = Pipeline([\n",
    "    ('ratio', FunctionTransformer(get_ratio, validate=False, kw_args={'columns': [0, 1]})),\n",
    "    ('log', FunctionTransformer(log_positive, validate=False, kw_args={'columns': [0, 1]}))\n",
    "]),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Apply the pipeline to the data\n",
    "X_transformed = pipeline.fit_transform(X)\n",
    "\n",
    "# Print the transformed data\n",
    "print(X_transformed)\n",
    "\n",
    "#This code will create a pipeline that first applies the log_positive function to the specified columns, and then standardizes the data using the StandardScaler class. It will then apply the pipeline to the data X and print the transformed data to the console.\n",
    "\n",
    "#You can use a different set of transformations in place of logarithmization and standardization, as needed. You can also specify the columns to be transformed by passing the columns parameter to the FunctionTransformer constructor, or you can use a different transformer class to apply a different set of transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) to select the top 2 features\n",
    "rfe = RFE(model, 2)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and test data using the selected features\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Train the model on the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the selected features of the test data\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "############################################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be an empty list\n",
    "selected_features = []\n",
    "\n",
    "# Set the maximum number of features to select\n",
    "max_features = 2\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "for i in range(1, len(feature_indices) + 1):\n",
    "    for combination in combinations(feature_indices, i):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, combination]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            selected_features = combination\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)\n",
    "##########################################\n",
    "#BACKWARD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Create a list of all the feature indices\n",
    "feature_indices = list(range(X.shape[1]))\n",
    "\n",
    "# Set the initial set of features to be all the features\n",
    "selected_features = feature_indices\n",
    "\n",
    "# Set the minimum number of features to select\n",
    "min_features = 1\n",
    "\n",
    "# Initialize the best cross-validated score to be negative infinity\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over all possible combinations of features\n",
    "while len(selected_features) > min_features:\n",
    "    scores = []\n",
    "    for i in range(len(selected_features)):\n",
    "        # Select the current combination of features\n",
    "        X_selected = X[:, selected_features]\n",
    "        \n",
    "        # Train a logistic regression model with 5-fold cross-validation\n",
    "        model = LogisticRegression()\n",
    "        score = cross_val_score(model, X_selected, y, cv=5).mean()\n",
    "        \n",
    "        # Add the score for the current combination of features\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Find the index of the feature with the lowest score\n",
    "    worst_feature_index = np.argmin(scores)\n",
    "    \n",
    "    # If the current combination of features has a higher cross-validated score than the best score, update the best score and the selected features\n",
    "    if scores[worst_feature_index] > best_score:\n",
    "        best_score = scores[worst_feature_index]\n",
    "        selected_features = selected_features[:worst_feature_index] + selected_features[worst_feature_index + 1:]\n",
    "    else:\n",
    "        # If the current combination of features has a lower cross-validated score than the best score, stop the search\n",
    "        break\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-be82a844217a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Standardize the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dd40e4e7e366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit different models and evaluate their performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m models = [\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit different models and evaluate their performance\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"{model.__class__.__name__}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STACKING\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "# Define the second-level model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Define the stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = stacking_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "  \n",
    "pca = PCA(n_components = 2)\n",
    "  \n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "  \n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index: [0 1 2 3 4 6 7 9] Test index: [5 8]\n",
      "Train index: [0 1 2 3 4 5 6 8] Test index: [7 9]\n",
      "Train index: [0 2 4 5 6 7 8 9] Test index: [1 3]\n",
      "Train index: [1 3 4 5 6 7 8 9] Test index: [0 2]\n",
      "Train index: [0 1 2 3 5 7 8 9] Test index: [4 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING AS PREPROCESSING DATA INTO CLASSIFICATION PROBLEM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "y = [0, 1, 0, 1, 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use KMeans to cluster the training data into 3 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the training data\n",
    "X_train_clustered = np.concatenate((X_train, kmeans.labels_.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Create a Random Forest classifier and train it on the clustered data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_clustered, y_train)\n",
    "\n",
    "# Add the cluster labels as a new feature in the test data\n",
    "X_test_clustered = np.concatenate((X_test, kmeans.predict(X_test).reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to pick the optimal number of clusters for a clustering algorithm is to use an evaluation metric that compares the quality of different clusterings. There are many such metrics available, such as the silhouette score, the Calinski-Harabasz index, and the Davies-Bouldin index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Try clustering the data with different numbers of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.predict(X)\n",
    "\n",
    "    # Calculate the silhouette score for this number of clusters\n",
    "    score = silhouette_score(X, cluster_labels)\n",
    "    print(\"Number of clusters:\", n_clusters, \"Silhouette score:\", score)\n",
    "    \n",
    "    ###################\n",
    "#PROF DOC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "(\"kmeans\", KMeans(n_clusters=50)),\n",
    "(\"log_reg\", LogisticRegression()),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "Let’s look at the best value for k and the performance of the resulting pipeline:\n",
    ">>> grid_clf.best_params_\n",
    "{'kmeans__n_clusters': 99}\n",
    ">>> grid_clf.score(X_test, y_test)\n",
    "0.9822222222222222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
    "\n",
    "# Create a PCA object and fit it to the data\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "# Plot the explained variance ratio as a function of the number of dimensions\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of dimensions')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-66b1c0fdbc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Choose the optimal number of dimensions based on the explained variance ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Transform the training and test data using the chosen number of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pca' is not defined"
     ]
    }
   ],
   "source": [
    "# Choose the optimal number of dimensions based on the explained variance ratio\n",
    "n_dimensions = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "\n",
    "# Transform the training and test data using the chosen number of dimensions\n",
    "X_train_transformed = pca.transform(X_train)[:, :n_dimensions]\n",
    "X_test_transformed = pca.transform(X_test)[:, :n_dimensions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different types of clustering algorithms, but some of the most common ones include:\n",
    "\n",
    "    K-means clustering: This is a centroid-based algorithm that divides a dataset into a predefined number of clusters by minimizing the sum of squared distances between the points and the cluster centroids.\n",
    "\n",
    "    Hierarchical clustering: This is an agglomerative algorithm that builds a hierarchy of clusters by iteratively merging the closest pairs of clusters.\n",
    "\n",
    "    DBSCAN: This is a density-based algorithm that divides a dataset into clusters based on the density of the points. It is able to identify clusters of different shapes and sizes and can handle noisy or outlier points.\n",
    "\n",
    "    Expectation-maximization (EM): This is a probabilistic algorithm that estimates the underlying distribution of the data and uses it to identify clusters.\n",
    "\n",
    "    Affinity propagation: This is a message-passing algorithm that identifies clusters by exchanging messages between pairs of points until a consensus is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
